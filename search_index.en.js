window.searchIndex = {"fields":["title","body"],"pipeline":["trimmer","stopWordFilter","stemmer"],"ref":"id","version":"0.9.5","index":{"body":{"root":{"docs":{},"df":0,"0":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.4641016151377544}},"df":1,".":{"docs":{},"df":0,"0":{"docs":{},"df":0,"5":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}},"1":{"docs":{},"df":0,".":{"docs":{},"df":0,"0":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}}}}},"5":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"8":{"docs":{},"df":0,"9":{"docs":{},"df":0,"9":{"docs":{},"df":0,"2":{"docs":{},"df":0,"3":{"docs":{},"df":0,"4":{"docs":{},"df":0,"3":{"docs":{},"df":0,"7":{"docs":{},"df":0,"8":{"docs":{},"df":0,"8":{"docs":{},"df":0,"5":{"docs":{},"df":0,"8":{"docs":{},"df":0,"9":{"docs":{},"df":0,"7":{"docs":{},"df":0,"7":{"docs":{},"df":0,"5":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}},"9":{"docs":{},"df":0,"8":{"docs":{},"df":0,"9":{"docs":{},"df":0,"8":{"docs":{},"df":0,"7":{"docs":{},"df":0,"4":{"docs":{},"df":0,"0":{"docs":{},"df":0,"4":{"docs":{},"df":0,"2":{"docs":{},"df":0,"9":{"docs":{},"df":0,"7":{"docs":{},"df":0,"3":{"docs":{},"df":0,"5":{"docs":{},"df":0,"7":{"docs":{},"df":0,"3":{"docs":{},"df":0,"7":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"1":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,".":{"docs":{},"df":0,"0":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1},"1":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"2":{"docs":{},"df":0,"5":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"7":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"0":{"docs":{},"df":0,"0":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"4":{"docs":{},"df":0,"8":{"docs":{},"df":0,"5":{"docs":{},"df":0,"5":{"docs":{},"df":0,".":{"docs":{},"df":0,"0":{"docs":{},"df":0,"1":{"docs":{},"df":0,"6":{"docs":{},"df":0,"2":{"docs":{},"df":0,"8":{"docs":{},"df":0,"8":{"docs":{},"df":0,"0":{"docs":{},"df":0,"3":{"docs":{},"df":0,"4":{"docs":{},"df":0,"1":{"docs":{},"df":0,"2":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}},"1":{"docs":{},"df":0,".":{"docs":{},"df":0,"2":{"docs":{},"df":0,"3":{"docs":{},"df":0,"8":{"docs":{},"df":0,"7":{"docs":{},"df":0,"0":{"docs":{},"df":0,"0":{"docs":{},"df":0,"9":{"docs":{},"df":0,"0":{"docs":{},"df":0,"6":{"docs":{},"df":0,"3":{"docs":{},"df":0,"4":{"docs":{},"df":0,"4":{"docs":{},"df":0,"3":{"docs":{},"df":0,"8":{"docs":{},"df":0,"2":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}},"2":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1},"4":{"docs":{},"df":0,"6":{"docs":{},"df":0,"9":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"5":{"docs":{},"df":0,"1":{"docs":{},"df":0,"2":{"docs":{},"df":0,".":{"docs":{},"df":0,"0":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"6":{"docs":{},"df":0,"6":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"2":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,".":{"docs":{},"df":0,"0":{"docs":{},"df":0,".":{"docs":{},"df":0,"3":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"1":{"docs":{},"df":0,"2":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"/":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}}}}},"4":{"docs":{},"df":0,"2":{"docs":{},"df":0,"8":{"docs":{},"df":0,"6":{"docs":{},"df":0,"6":{"docs":{},"df":0,"4":{"docs":{},"df":0,"5":{"docs":{},"df":0,"7":{"docs":{},"df":0,"e":{"docs":{},"df":0,"8":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"0":{"docs":{},"df":0,"2":{"docs":{},"df":0,"2":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}},"2":{"docs":{},"df":0,"0":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"3":{"docs":{},"df":0,".":{"docs":{},"df":0,"3":{"docs":{},"df":0,".":{"docs":{},"df":0,"2":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,"/":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"j":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"x":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"4":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"0":{"docs":{},"df":0,".":{"docs":{},"df":0,"8":{"docs":{},"df":0,"7":{"docs":{},"df":0,"3":{"docs":{},"df":0,"8":{"docs":{},"df":0,"4":{"docs":{},"df":0,"3":{"docs":{},"df":0,"4":{"docs":{},"df":0,"5":{"docs":{},"df":0,"9":{"docs":{},"df":0,"3":{"docs":{},"df":0,"7":{"docs":{},"df":0,"8":{"docs":{},"df":0,"7":{"docs":{},"df":0,"6":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}},"9":{"docs":{},"df":0,"2":{"docs":{},"df":0,"0":{"docs":{},"df":0,".":{"docs":{},"df":0,"1":{"docs":{},"df":0,"0":{"docs":{},"df":0,"9":{"docs":{},"df":0,"9":{"docs":{},"df":0,"9":{"docs":{},"df":0,"9":{"docs":{},"df":0,"9":{"docs":{},"df":0,"9":{"docs":{},"df":0,"9":{"docs":{},"df":0,"9":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}},"v":{"docs":{},"df":0,"(":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"5":{"docs":{},"df":0,"6":{"docs":{},"df":0,"7":{"docs":{},"df":0,".":{"docs":{},"df":0,"0":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"9":{"docs":{},"df":0,"9":{"docs":{},"df":0,"8":{"docs":{},"df":0,"1":{"docs":{},"df":0,".":{"docs":{},"df":0,"8":{"docs":{},"df":0,"3":{"docs":{},"df":0,"6":{"docs":{},"df":0,"7":{"docs":{},"df":0,"4":{"docs":{},"df":0,"9":{"docs":{},"df":0,"8":{"docs":{},"df":0,"1":{"docs":{},"df":0,"4":{"docs":{},"df":0,"7":{"docs":{},"df":0,"7":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}},"7":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"0":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"8":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"9":{"docs":{},"df":0,"7":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"9":{"docs":{},"df":0,"5":{"docs":{},"df":0,"5":{"docs":{},"df":0,"3":{"docs":{},"df":0,"0":{"docs":{},"df":0,".":{"docs":{},"df":0,"0":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"]":{"docs":{},"df":0,"{":{"docs":{},"df":0,"1":{"docs":{},"df":0,"1":{"docs":{},"df":0,"}":{"docs":{},"df":0,"$":{"docs":{},"df":0,"\"":{"docs":{},"df":0,".":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"2":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"}":{"docs":{},"df":0,"$":{"docs":{},"df":0,"\"":{"docs":{},"df":0,".":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"/":{"docs":{},"df":0,"[":{"docs":{},"df":0,"0":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}},"4":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"}":{"docs":{},"df":0,"$":{"docs":{},"df":0,"\"":{"docs":{},"df":0,".":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"5":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,"}":{"docs":{},"df":0,"$":{"docs":{},"df":0,"\"":{"docs":{},"df":0,".":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}},"_":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"o":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1}},"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3,"_":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"3":{"docs":{},"df":0,".":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}}}},"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}},"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}},"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}}}},"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2,"a":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":3,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4}}}}},"f":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.605551275463989}},"df":1}}},"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}},"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2,"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1},"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2},"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1,"'":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}}},"l":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"b":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":3}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1}}}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":3}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"p":{"docs":{},"df":0,";":{"docs":{},"df":0,"&":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4},"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":1}},"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":1},"z":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}},"d":{"docs":{},"df":0,"/":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":4.242640687119285},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.8284271247461903}},"df":2}}}},"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}},"s":{"docs":{},"df":0,"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"y":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3}},"r":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2},"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"'":{"docs":{},"df":0,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":4,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}},"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"(":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}}},"v":{"docs":{"https://egordmitriev.dev/archive/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"'":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":2}}}}}},"i":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"m":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{},"df":0,"[":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":2}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}},"u":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":3,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"_":{"docs":{},"df":0,"b":{"docs":{},"df":0,"y":{"docs":{},"df":0,"=":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"(":{"docs":{},"df":0,"'":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,".":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"w":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":1}}}}}}},"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1},"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2}}},"g":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"_":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"'":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"_":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}}},"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.3166247903554},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":4.358898943540674},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":4.47213595499958}},"df":4,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,":":{"docs":{},"df":0,":":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,":":{"docs":{},"df":0,":":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}},"z":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":1}}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":3.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"h":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}}},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"a":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":4,"e":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":2}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":2}}}},"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979}},"df":1}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}},"t":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.3166247903554},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":4}}}}}},"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1}}}}}},"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}},"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1,"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"3":{"docs":{},"df":0,".":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.605551275463989},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":7}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/":{"tf":1.0}},"df":1}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":3,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}},"n":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.8284271247461903}},"df":1,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"f":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"{":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":5},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2}}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}},"s":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}},"z":{"docs":{},"df":0,"z":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"y":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979}},"df":3}}},"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2}},"n":{"docs":{},"df":0,"'":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":2}},"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2}}}},"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":4}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}},"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}},"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1,"k":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.1622776601683795}},"df":1,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}}}},"f":{"docs":{},"df":0,"n":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}}}},"n":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":4,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"g":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":7.416198487095663},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":4.242640687119285}},"df":4,"(":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,".":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0}},"df":1}}}}}}}}}}}}}}}}},"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,".":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}},"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}},"o":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"k":{"docs":{},"df":0,"=":{"docs":{},"df":0,"2":{"docs":{},"df":0,"3":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"4":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}},"l":{"docs":{},"df":0,"1":{"docs":{},"df":0,"0":{"docs":{},"df":0,"0":{"docs":{},"df":0,"k":{"docs":{},"df":0,"_":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}},"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.449489742783178}},"df":2,"i":{"docs":{},"df":0,"f":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"u":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1}},"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.3166247903554}},"df":1},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3,"r":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.8284271247461903}},"df":1}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.605551275463989},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.7416573867739413}},"df":3,"=":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"/":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"/":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"/":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,")":{"docs":{},"df":0,"]":{"docs":{},"df":0,"(":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"p":{"docs":{},"df":0,"s":{"docs":{},"df":0,":":{"docs":{},"df":0,"/":{"docs":{},"df":0,"/":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"/":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"b":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"/":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":2}}},"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.872983346207417},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4}}},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":3},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2,"=":{"docs":{},"df":0,"[":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"p":{"docs":{},"df":0,"y":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"3":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}},"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}},"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.605551275463989},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":4,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}},"x":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":2}}},"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4},"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":3}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}},"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.4641016151377544},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":4.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5}},"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}}},"r":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}},"u":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}},"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}},"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"_":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2}}}}},"u":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3,"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"x":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.1622776601683795}},"df":1}}},"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979}},"df":2}},"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2}}}},"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"y":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":2}}}}}},"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"(":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":4}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":4.47213595499958},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1}}}},"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2}}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}}}}}},"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979}},"df":1,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,"(":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3,"_":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":4}}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":2}}}}},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":2}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":9.433981132056603},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":11.74734012447073},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":11.789826122551595}},"df":6,"'":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"/":{"docs":{},"df":0,"y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"=":{"docs":{},"df":0,"2":{"docs":{},"df":0,"0":{"docs":{},"df":0,"2":{"docs":{},"df":0,"2":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"0":{"docs":{},"df":0,"1":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":1}}}},"f":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":1}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":5.0990195135927845},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":3}}},"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}},"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"y":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}},"b":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":2,"'":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1},"u":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1}}},"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1}}},"o":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.0}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"q":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":4.47213595499958},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3,"'":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"_":{"docs":{},"df":0,"2":{"docs":{},"df":0,".":{"docs":{},"df":0,"1":{"docs":{},"df":0,"2":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}}}}}},"f":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":2,"a":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979}},"df":2,"_":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"f":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,".":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":3,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.4641016151377544}},"df":1}}}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"v":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":5}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"y":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":5.385164807134504}},"df":1}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":5}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979}},"df":1}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.605551275463989},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":3.1622776601683795}},"df":2}},"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5}}}}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1}}}}}}},"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":3}}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2}}},"o":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3}}}}}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"n":{"docs":{},"df":0,"'":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}}}}},"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":4.242640687119285}},"df":1,"_":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,".":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"f":{"docs":{},"df":0,"'":{"docs":{},"df":0,"{":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"df":0,"'":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3},"":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"w":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":2}}}}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"o":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":1}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":3}}}},"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4}},"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"s":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":2}},"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2}}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"c":{"docs":{},"df":0,"2":{"docs":{},"df":0,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1}}}}}}}}}}}}}},"v":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,".":{"docs":{},"df":0,"f":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":2}}}}}}},"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}},"d":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":5}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2}}}}},"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}}}}}}},"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"m":{"docs":{},"df":0,"o":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":4.69041575982343},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}},"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"y":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1},"y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":4.123105625617661}},"df":1},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"3":{"docs":{},"df":0,".":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"3":{"docs":{},"df":0,"_":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"l":{"docs":{},"df":0,"=":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":5}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":3}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.449489742783178}},"df":5}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":2}}}}}}},"i":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}}}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":2}}}}}},"i":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}},"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":2}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":3}}},"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"y":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"x":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"p":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":4,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}},"c":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"l":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2},"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.3166247903554},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.449489742783178}},"df":4,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":3}},"n":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"s":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}}}},"y":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"b":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"f":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"/":{"docs":{},"df":0,"{":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{},"df":0,"}":{"docs":{},"df":0,"/":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"{":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}},".":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"p":{"docs":{},"df":0,"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"(":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}},"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979}},"df":1,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"k":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2},"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.4641016151377544}},"df":1,"e":{"docs":{},"df":0,")":{"docs":{},"df":0,".":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4}}}},"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"e":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":3}}},"l":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,".":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,".":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"y":{"docs":{},"df":0,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2}},"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}},"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":6,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2},"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}},"x":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}},"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.449489742783178}},"df":4}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":4,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}},"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}}},"r":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}},"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}}}}},"m":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2,"=":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"s":{"docs":{},"df":0,"k":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}},"e":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}},"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,".":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5}}}}},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}}},"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":2}}}}},"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3}},"m":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3},"r":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}},"d":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.3166247903554},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":5}}},"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2,"@":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,":":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"m":{"docs":{},"df":0,"/":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}},"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":3}}}},"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":4,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.8284271247461903}},"df":2}}},"o":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"e":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"o":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":2},"g":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":2}}}}},"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907}},"df":1}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}},"p":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}},"s":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1}}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":2,"n":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":2},"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}}},"x":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":1},"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,".":{"docs":{},"df":0,"t":{"docs":{},"df":0,"g":{"docs":{},"df":0,"z":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}},"3":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,".":{"docs":{},"df":0,"t":{"docs":{},"df":0,"g":{"docs":{},"df":0,"z":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}},"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"r":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}},"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"(":{"docs":{},"df":0,"_":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3,"n":{"docs":{},"df":0,"'":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}},"d":{"docs":{},"df":0,"f":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"l":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"r":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"v":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0}},"df":1}},"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":4}},"r":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":5,"":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"y":{"docs":{"https://egordmitriev.dev/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":3,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"o":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}},"p":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1},"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"p":{"docs":{},"df":0,"s":{"docs":{},"df":0,":":{"docs":{},"df":0,"/":{"docs":{},"df":0,"/":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{},"df":0,"c":{"docs":{},"df":0,"d":{"docs":{},"df":0,"n":{"docs":{},"df":0,".":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"/":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"/":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"/":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"/":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"/":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"/":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"/":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"n":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"/":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}},"y":{"docs":{},"df":0,"b":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"'":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0}},"df":3},"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},".":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2},"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,".":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"y":{"docs":{},"df":0,".":{"docs":{},"df":0,"f":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"y":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"=":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"v":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}},"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"v":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"f":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.449489742783178}},"df":4}}}}}}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0}},"df":2,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,"=":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":4}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4}}}}},"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":5}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}}},"o":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"c":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}}},"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1}}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"=":{"docs":{},"df":0,"2":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}},"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}},"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.3166247903554},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":4,"_":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":2}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4},"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":3,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"=":{"docs":{},"df":0,"1":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}}},"u":{"docs":{},"df":0,"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":3.4641016151377544},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":3.3166247903554}},"df":5}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":3}}},"n":{"docs":{"https://egordmitriev.dev/":{"tf":1.0}},"df":1},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5}}}}}},"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}},"u":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}},"k":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"l":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5}}}}},"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}},"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"2":{"docs":{},"df":0,".":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"r":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"1":{"docs":{},"df":0,"0":{"docs":{},"df":0,".":{"docs":{},"df":0,"0":{"docs":{},"df":0,".":{"docs":{},"df":0,"0":{"docs":{},"df":0,".":{"docs":{},"df":0,"0":{"docs":{},"df":0,"/":{"docs":{},"df":0,"1":{"docs":{},"df":0,"6":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"\\":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}}}}}}}}},"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"`":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"\\":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.0}},"df":1}},"":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":4}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.449489742783178}},"df":3},"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2}}}},"":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979}},"df":1}}},"j":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0}},"df":1},"v":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":2}}},"o":{"docs":{},"df":0,"b":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"y":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979}},"df":1,".":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,".":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"k":{"docs":{},"df":0,"a":{"docs":{},"df":0,"f":{"docs":{},"df":0,"k":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}},"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":4}},"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"y":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2,"=":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":3}}}},"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}}},"l":{"docs":{},"df":0,"2":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"a":{"docs":{},"df":0,"b":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"g":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1},"k":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1,"4":{"docs":{},"df":0,"j":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":5.0}},"df":1}}}}},"r":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979}},"df":1}},"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3},"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}},"x":{"docs":{"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0}},"df":1}}}},"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"k":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.8284271247461903}},"df":3}}},"f":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"g":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5},"":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":3.0}},"df":4},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":2}}}}}},"i":{"docs":{"https://egordmitriev.dev/":{"tf":1.0}},"df":1,"b":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}}},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"y":{"docs":{},"df":0,"c":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.449489742783178}},"df":3}}},"n":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":8.12403840463596}},"df":2},"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"x":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2,".":{"docs":{},"df":0,"g":{"docs":{},"df":0,"z":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178}},"df":1}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178}},"df":1}},"v":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":6.4031242374328485}},"df":1}},"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":3}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}},"g":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,".":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5},"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1},"s":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2},"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5}}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.0}},"df":3}}}},"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.449489742783178}},"df":3}}},"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}},"k":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":3.1622776601683795}},"df":5}},"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":4,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"y":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"=":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,":":{"docs":{},"df":0,"a":{"docs":{},"df":0,"w":{"docs":{},"df":0,"s":{"docs":{},"df":0,":":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,":":{"docs":{},"df":0,":":{"docs":{},"df":0,"a":{"docs":{},"df":0,"w":{"docs":{},"df":0,"s":{"docs":{},"df":0,":":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"y":{"docs":{},"df":0,"/":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979}},"df":3,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}},"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2},"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"z":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"x":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"z":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"3":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,"(":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":3,"(":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979}},"df":3}}}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}}}},"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":1}}}}},"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":5.656854249492381},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":3.0}},"df":3,"[":{"docs":{},"df":0,"_":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}},"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":2,"/":{"docs":{},"df":0,"a":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}}}}}},"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2},"i":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2,"u":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1,"(":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"x":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979}},"df":1},"o":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"e":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}},"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":7.416198487095663},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4},"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.6457513110645907}},"df":3}}}},"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":5}},"s":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"b":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}},"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"p":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2}}}}}}},"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"y":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":3,"=":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}},"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"1":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}},"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":2}}}}}}},"e":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":4}},"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"w":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":4},"x":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4}}},"l":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5}}},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1}}}}},"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}},"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}}},"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"_":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"3":{"docs":{},"df":0,".":{"docs":{},"df":0,"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,".":{"docs":{},"df":0,"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979}},"df":2}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.6457513110645907}},"df":2}},"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.4641016151377544},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":5,"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"(":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"f":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4,"a":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"b":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"/":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":1,"e":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2},"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2}}}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":3.605551275463989}},"df":4,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}}}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5}}}}}}},"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,"w":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":4,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4,"_":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}},"s":{"docs":{},"df":0,"/":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":3}}}},"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"k":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2}}}},"g":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}},"i":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":2}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,")":{"docs":{},"df":0,"3":{"docs":{},"df":0,"2":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.449489742783178}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"[":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1,"(":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,".":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0}},"df":1}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3},"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2,"(":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"=":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"$":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,":":{"docs":{},"df":0,"/":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"r":{"docs":{},"df":0,"/":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"/":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"/":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":3,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"(":{"docs":{},"df":0,"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}},"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}},"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":8.06225774829855},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":4.358898943540674},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.449489742783178}},"df":5,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"c":{"docs":{},"df":0,"f":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"=":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"_":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"=":{"docs":{},"df":0,"{":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"y":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"=":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0}},"df":1,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"'":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2},"t":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3}}}}},"y":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}},"o":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"r":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3}}}}},"s":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2}}}},"t":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3}}}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":4}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.449489742783178}},"df":3}}}}},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":2}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}}}},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}},"r":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"s":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,"(":{"docs":{},"df":0,"f":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}},"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}},"c":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":3.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":3.0}},"df":5,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}}}},"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1}}}},"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.449489742783178}},"df":3,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5,"'":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178}},"df":1}}},"n":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":3}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1}}}},"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2},"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":3.3166247903554}},"df":5}}},"x":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}},"_":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}},"s":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5}}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.449489742783178}},"df":1}}}}},"s":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"y":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":6.557438524302},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":6.6332495807108},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":3.605551275463989}},"df":4}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2}}}}}}},"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1},"i":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":3}},"r":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"w":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1,"d":{"docs":{},"df":0,"f":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,".":{"docs":{},"df":0,"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}},"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"/":{"docs":{},"df":0,"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3,"i":{"docs":{},"df":0,"z":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}},"v":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"d":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4}}},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,".":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":1}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"o":{"docs":{},"df":0,"f":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"y":{"docs":{},"df":0,"(":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"x":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"b":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"y":{"docs":{},"df":0,"=":{"docs":{},"df":0,"c":{"docs":{},"df":0,"d":{"docs":{},"df":0,"k":{"docs":{},"df":0,".":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"y":{"docs":{},"df":0,".":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"y":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"h":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"o":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,"r":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.6457513110645907}},"df":1}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":5}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":4,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"'":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}},"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"c":{"docs":{},"df":0,"f":{"docs":{},"df":0,"n":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1},"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.6457513110645907}},"df":4}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979}},"df":1}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}},"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}},"s":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":1}}}},"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"l":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.4641016151377544},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2,"=":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"f":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"{":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}},"w":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,".":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"(":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"w":{"docs":{},"df":0,"d":{"docs":{},"df":0,"f":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":3,"_":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}},"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.605551275463989},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.3166247903554},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.449489742783178}},"df":4,"e":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0}},"df":2}}}}},"w":{"docs":{},"df":0,"k":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"\"":{"docs":{},"df":0,"$":{"docs":{},"df":0,"{":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"\"":{"docs":{},"df":0,")":{"docs":{},"df":0,"}":{"docs":{},"df":0,"/":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"}":{"docs":{},"df":0,"/":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}},"3":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":2,".":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}},"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":7.280109889280518}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,".":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}}},"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}},"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"y":{"docs":{},"df":0,"(":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}},"k":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178}},"df":1}},"m":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1},"p":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}},"v":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"$":{"docs":{},"df":0,"{":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"\"":{"docs":{},"df":0,")":{"docs":{},"df":0,"}":{"docs":{},"df":0,"/":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"w":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"(":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"$":{"docs":{},"df":0,"{":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"\"":{"docs":{},"df":0,")":{"docs":{},"df":0,"}":{"docs":{},"df":0,"/":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"y":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"b":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979}},"df":1}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,":":{"docs":{},"df":0,"2":{"docs":{},"df":0,".":{"docs":{},"df":0,"1":{"docs":{},"df":0,"2":{"docs":{},"df":0,".":{"docs":{},"df":0,"1":{"docs":{},"df":0,"5":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}},"c":{"docs":{},"df":0,":":{"docs":{},"df":0,"2":{"docs":{},"df":0,".":{"docs":{},"df":0,"1":{"docs":{},"df":0,"2":{"docs":{},"df":0,".":{"docs":{},"df":0,"1":{"docs":{},"df":0,"5":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"m":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":4.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.8284271247461903}},"df":2,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1,".":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"(":{"docs":{},"df":0,"1":{"docs":{},"df":0,"0":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}}},"e":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1}}}}}}}}}}}}}},"d":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.6457513110645907}},"df":1}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1}}}},"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}},"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0}},"df":3,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1},"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"f":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.605551275463989},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}},"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{},"df":0,"_":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"v":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{},"df":0,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"_":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,".":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"_":{"docs":{},"df":0,"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,".":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"v":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979}},"df":1}}},"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.0}},"df":1}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":3}}},"q":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178}},"df":1,"(":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}},"2":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"q":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178}},"df":1}}}},"[":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"[":{"docs":{},"df":0,"_":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}},"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.3166247903554},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}}}},"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1},"v":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"'":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.449489742783178}},"df":4,"u":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}}},"g":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}},"o":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2},"r":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"n":{"docs":{},"df":0,"'":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1}}}}}},"w":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"g":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}}}}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":4}}}}}},"p":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"f":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"z":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}},"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"f":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}},"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2}}}}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979}},"df":2}},"f":{"docs":{},"df":0,"t":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}},"l":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.3166247903554}},"df":1},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}},"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"2":{"docs":{},"df":0,".":{"docs":{},"df":0,"0":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}}},"w":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}},"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}},"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":3.4641016151377544},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":5,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1}},"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":4.795831523312719},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3,".":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"f":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2}}}},"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":2}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}},"q":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2}},"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,".":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"f":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2}},"g":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2}},"l":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"(":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":4}},"t":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.4641016151377544},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"y":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.7416573867739413},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,".":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}},"f":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"[":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}},"o":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}},"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3},"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.0}},"df":1,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":3}}}}}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}}}}}},"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0}},"df":1}}},"f":{"docs":{},"df":0,"f":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"2":{"docs":{},"df":0,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}},"w":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"f":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}},"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.4641016151377544},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5}},"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}},"o":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178}},"df":2,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"j":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}},"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2,"_":{"docs":{},"df":0,"{":{"docs":{},"df":0,"i":{"docs":{},"df":0,"=":{"docs":{},"df":0,"1":{"docs":{},"df":0,"}":{"docs":{},"df":0,"^":{"docs":{},"df":0,"{":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0}},"df":1}}}}}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}},"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":4}},"s":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1},"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"y":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"(":{"docs":{},"df":0,"1":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}}}}},"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"(":{"docs":{},"df":0,"0":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"1":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"2":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":4}}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"5":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.23606797749979}},"df":3}},"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"[":{"docs":{},"df":0,"c":{"docs":{},"df":0,"d":{"docs":{},"df":0,"k":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"f":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}},"k":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4}},"l":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}},"m":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"/":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"s":{"docs":{},"df":0,"/":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1}}}}}}}}}},"s":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":5.0990195135927845},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3,"s":{"docs":{},"df":0,"|":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}},"x":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":1,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2},"q":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0}},"df":1}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}}}}}},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":5.656854249492381},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}},"x":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":4.358898943540674}},"df":1}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2},"":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}}}}},"y":{"docs":{},"df":0,"'":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1},"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3},"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":3,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}}}},"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"m":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}}},"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":6.082762530298219}},"df":1}}},"o":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":4.242640687119285},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":4.358898943540674}},"df":5}},"p":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":1},"k":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":3.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}},"d":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}}},"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.3166247903554},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":2}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.605551275463989},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":3.3166247903554}},"df":4}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":2}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}},"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":1,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":3}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"[":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"f":{"docs":{},"df":0,"n":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}},"r":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"o":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5}},"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}}}}},"u":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.449489742783178}},"df":4}}}}}}}},"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}}}}},"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}},"f":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":1}},"q":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":3},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"k":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}},"n":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979}},"df":1}}}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}},"p":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":4,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}},"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":4.898979485566356},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":4.69041575982343},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":4.58257569495584},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":4.242640687119285},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":5,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":1}},"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.1622776601683795},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"'":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"f":{"docs":{},"df":0,"n":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{},"df":0,"(":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}},"":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"(":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"df":0,"/":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"/":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":4}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":4.358898943540674}},"df":1,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":3.1622776601683795}},"df":2,"d":{"docs":{},"df":0,"f":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,".":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":5,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}},"e":{"docs":{},"df":0,"=":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}},"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0}},"df":1,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":5}}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":3.3166247903554}},"df":1}}}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"b":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":2,"f":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"i":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":1,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}},"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":3.3166247903554}},"df":1,"e":{"docs":{},"df":0,".":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":2,"=":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"0":{"docs":{},"df":0,".":{"docs":{},"df":0,"2":{"docs":{},"df":0,"3":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"=":{"docs":{},"df":0,"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"o":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":3}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.7320508075688772}},"df":2}},"o":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":3}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":2}}}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979}},"df":1}}}}}}}},"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":2}}}},"p":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":3.4641016151377544}},"df":1,"_":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"=":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"v":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{},"df":0,".":{"docs":{},"df":0,"v":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{},"df":0,"_":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1,"=":{"docs":{},"df":0,"f":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"{":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}},"v":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{},"df":0,"_":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}},"w":{"docs":{},"df":0,"0":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"1":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}},"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"k":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}}},"n":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":4}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}}},"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0}},"df":1}}},"y":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.8284271247461903},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":4}},"e":{"docs":{},"df":0,"'":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1},"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}},"b":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}},"l":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.4142135623730951}},"df":5}},"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}},"":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"v":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951}},"df":1},"":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"a":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":3}}}}},"o":{"docs":{},"df":0,"'":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"l":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":2}}}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":4}},"l":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1},"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{},"df":0,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/":{"tf":1.0},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.23606797749979},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.6457513110645907},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.0}},"df":6,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"(":{"docs":{},"df":0,"\"":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}},"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"'":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":5.830951894845301}},"df":1,"2":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}},"k":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":4.242640687119285},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.7320508075688772}},"df":5,"f":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":2.8284271247461903}},"df":4}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":2}}}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0},"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":5}},"t":{"docs":{},"df":0,"h":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.4142135623730951}},"df":3}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"n":{"docs":{},"df":0,"'":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.4142135623730951},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":2.449489742783178},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":2.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":2.0}},"df":4},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}}}},"x":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"8":{"docs":{},"df":0,"6":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"_":{"docs":{},"df":0,"6":{"docs":{},"df":0,"4":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"_":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0}},"df":1}},"v":{"docs":{},"df":0,"f":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1,"=":{"docs":{},"df":0,"2":{"docs":{},"df":0,"0":{"docs":{},"df":0,"2":{"docs":{},"df":0,"0":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"*":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}},"1":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"*":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}},"2":{"docs":{},"df":0,"/":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"_":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"_":{"docs":{},"df":0,"*":{"docs":{},"df":0,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"'":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":2.23606797749979}},"df":1},"v":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":2}}}}},"":{"docs":{},"df":0,"r":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.7320508075688772}},"df":1},"v":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.4142135623730951}},"df":1}}}}},"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.4142135623730951}},"df":1}}}}},"title":{"root":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"https://egordmitriev.dev/archive/":{"tf":1.0}},"df":1}}}}}},"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/":{"tf":1.0}},"df":1}}}},"c":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}}}},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":3}}},"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"y":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"tf":1.0}},"df":1}}}}}}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/":{"tf":1.0}},"df":1}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"tf":1.0}},"df":2}}}}}}},"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"s":{"docs":{"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"tf":1.0}},"df":1}},"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://egordmitriev.dev/blog/hello-world/":{"tf":1.0}},"df":1}}}}}}}},"documentStore":{"save":true,"docs":{"https://egordmitriev.dev/":{"body":"Hey there, I'm Egor - a data engineer and machine learning enthusiast who loves pushing boundaries and exploring new technologies. My expertise lies in graph machine learning and database internals. Follow along as occasionally I share my insights and experiences with within my blog.\n","id":"https://egordmitriev.dev/","title":"Latest posts"},"https://egordmitriev.dev/archive/":{"body":"","id":"https://egordmitriev.dev/archive/","title":"Archive"},"https://egordmitriev.dev/blog/":{"body":"","id":"https://egordmitriev.dev/blog/","title":"Blog"},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"body":"\nOriginaly published as part of Luminis AI Blog.\n\nIntroduction\nLarge language models (LLMs) are all the buzz these days. From big corporations like Microsoft enhancing their office products to Snapchat having an assistant for entertainment, to high schoolers trying to cheat their assignments. Everyone is trying to incorporate LLMs into their products, services, and workflow.\nWith the surge in popularity, there's a flurry of discussions, blogs, and news articles about fine-tuning these models and their myriad applications. Even if you've dipped your toes into the LLM pool, you might find yourself stumbling upon unfamiliar terms and concepts.\nIn this three-part blog series, we'll map out all the key concepts related to LLMs, so you can finally understand what your ML enthusiast colleague is talking about, but also potentially incorporate these powerful models into your projects. So, buckle up, and let's dive into the fascinating world of Large Language Models!\nPrior Knowledge\nBefore we dive deeper into the key LLM concepts, it's helpful to cover some foundational background knowledge. This will ensure we're all on the same page as we explore the intricacies of LLMs.\nTokens\nLet's start with a simple question: how would you split a sentence into words? Seems straightforward, right? But what if the sentence uses contractions like \"can't\" or \"I'm\"? And what if we switch to a different language, say, Swedish or Polish? Would you split it the same way?\nThis is where the concept of \"tokenization\" comes into play. It's all about splitting text into smaller, discrete units (or \"tokens\"), preferably, in a reversible way. This provides a neat, organized way for our models to process the text.\nOne of the key properties of tokens is that they belong to a fixed-size set, aptly named the \"vocabulary\". This makes them much easier to work with mathematically. Each token can be represented by its unique ID in the set or as a one-hot vector.\n\n\n\n\n  \n  The document is tokenized and one-hot encoded producing a fixed-size matrix of vectors. These vectors are fed through a function that transforms them into embeddings, effectively reducing the dimensionality\n\n\nIn the olden days, tokenizers were quite lossy. It was common to work on stemmed words and only consider a set of the most common words. Modern tokenizers, instead, have evolved to focus on efficiency and losslessness. Instead of encoding whole words, algorithms such as Byte Pair Encoding (BPE) take a compression-like approach by breaking words apart.\nVocabulary construction is done in a purely data-driven manner, resulting in token splits that make sense semantically, such as the common verb ending \"-ing\". Words like \"working\", \"eating\", and \"learning\" all share this ending, thus an efficient encoding is to give \"-ing\" its own token. Some splits don't make sense, producing semantically dissimilar tokens such as \"lab-elling\" which requires the model to do more work to infer its true meaning.\n\n\n\n\n  \n  OpenAI's cl100k_base tokenizer encoding a sentence. In this case, 100k refers to its vocabulary size.\n\n\nBut what if a word doesn't exist in the vocabulary? Like \"w0rk1ng\"? In this case, the tokenizer breaks it down into smaller chunks, sometimes even character by character.\nNow, it's tempting to assume that a token corresponds to a word. And while that's often the case, it's not a hard and fast rule. For simplicity's sake, we'll often use the terms \"word\" and \"token\" interchangeably in this series. But remember, in the wild world of tokenization, a token could be anything from a whole word to a single character or a common word part.\nFor ballpark estimates of token count, you can multiply your word count by 1.25 (assuming English text). This gives a reasonable approximation of the number of tokens in a given piece of text. However, if you're looking for a more precise estimate, you can use the OpenAI tokenizer web tool.\nToken Embeddings\nNow that we've got our tokens, we need a way to represent them that captures more than just their identity. We've seen that tokens can be represented as one-hot vectors, which are great for basic math but not so helpful when it comes to comparing different words together. They don't capture the nuances of language, like how \"cat\" and \"dog\" are more similar to each other than \"cat\" and \"car\".\nEnter the concept of \"token embeddings\", also known as \"word vectors\". The seminal paper Word2Vec was instrumental in bringing this concept to the mainstream. The authors built on two key assumptions from prior work:\n\nSimilar words occur in the same context (a concept known as Distributional Semantics).\nSimilar words have similar meanings.\n\nIt's important to note that these two assumptions are distinct. The first is about the context in which words are used, while the second is about the meanings of the words themselves.\n\n\n\n\n  \n  Demonstration of Linear Relationships Between Words Visualized in Two Dimensional Space. Image from Google Blog\n\n\nAt first glance, \"similarity\" might seem like a subjective concept. But what if we think of words as high-dimensional vectors? Suddenly, similarity becomes a very concrete concept. It could be the L2 distance between vectors, the cosine similarity, the dot product similarity, and so on.\nIn the Word2Vec paper, the authors used gradient descent techniques to find embeddings for each word. The goal was to ensure that the above assumptions hold true when comparing these embeddings. In other words, they wanted to find a way to represent words as vectors in a high-dimensional space such that similar words (in terms of context and meaning) are close together in that space.\nThis was a game-changer in the field of natural language processing. Suddenly, we had a way to capture the richness and complexity of language in a mathematical form that machines could understand and work with. \nBut the real beauty of these embeddings is that they can capture relationships between words. For example, the vector difference between \"king\" and \"queen\" is similar to the difference between \"man\" and \"woman\". This suggests that the embeddings have learned something about the concept of gender.\nHowever, it's important to remember that these embeddings are not perfect. They are learned from data, and as such, they can reflect and perpetuate the biases present in that data. This is an important consideration when using these embeddings in real-world applications.\nEncoders and Decoders\nWhile methods like Word2Vec are great for creating simple word embeddings, they produce what we call \"shallow embeddings\". In this context, shallow means that a matrix of weights is trained directly, and thus can be used like a dictionary. As such, the number of possible embeddings is equal to the number of tokens in your vocabulary. This works fine when you're dealing with individual words, but it starts to break down when you're working with sentences or whole documents.\nWhy? Well, if you encode all the tokens in a sentence into embeddings, you lose all the order of the words. And as anyone who's ever played a game of \"Mad Libs\" knows, word order is crucial when it comes to making sense of a sentence. By losing the order, you also lose the context, which can drastically change the meaning of a word.\n\n\n\n\n  \n  The encoder produces a document embedding by combining the individual word embeddings\n\n\nTo overcome this limitation, we need an additional model, the \"Encoder\", which does some neural net math magic to create an embedding that takes both context and order into account.\nOn the other side of the equation, we have the \"Decoder\". Its job is to produce a token from the input, which is typically a latent vector.\n\n\n\n\n  \n  Visualization of a encoding a sequence of tokens embeddings into a single latent representation, and decoding it into a sequence of token probabilities.\n\n\nThe architecture of how Encoders and Decoders work can vary greatly. It can be based on Transformers, LSTMs, or a combination of both. We'll dive deeper into these architectures in a later blog.\nOne interesting thing to keep in mind is that, since encoders and decoders operate in latent space, their input is not limited to text. They can also take embeddings produced from images, audio, and other modalities. This is thanks to innovations like CLIP, which are trained on multimodal tasks by introducing an encoder for each data type.\n\n\n\n\n  \n  Inference process on NExT-GPT with text, image, audio, and video modalities.\n\nModeling Methods\nThe architecture of large language models isnt the only factor that gives them an edge. How they model natural language processing tasks also contributes greatly to their performance. Rather than taking a one-size-fits-all approach, large language models specialize in different modeling methods optimized for certain tasks.\nCausal Language Models (CLM)\nCausal Language Models (CLMs) are trained with an autoregressive objective, which is a fancy way of saying they're trained to predict the next token in a sequence based solely on the previous tokens. \nCLMs typically work in an unidirectional manner, meaning the next token depends only on the previous tokens. It's a bit like reading a book  you don't know what's coming next until you've read what's come before. Their architecture reflects this, as CLMs are typically decoder-only.\nBecause of their autoregressive nature, CLMs are great for tasks like text (and code) completion, chat, and story writing. Examples of CLMs include Generalized Pretrained Transformer (GPT), and its derivatives, such as Meta's Llama.\nMasked Language Models (MLM)\nOn the other hand, Masked Language Models (MLMs) are trained to predict masked tokens in a given input by randomly masking certain tokens during training. Its objective task is to fill in the blanks given a sentence, but complementary tasks are also used, like predicting which token has been replaced.\nUnlike CLMs, MLMs typically use a bidirectional architecture, meaning they use the context on both sides of a word. This gives them a broader perspective and generally leads to a better understanding of the relationships between words.\n\n\n\n\n  \n  Differences between attention direction. BERT uses a bi-directional Transformer. OpenAI GPT uses a unidirectional left-to-right Transformer\n\n\nMLMs are particularly suitable for tasks like text classification, sentiment analysis, and text tagging. Semantic search is driven by LLMs, where the mathematical distance between document embeddings us used as distance. However, they don't add much value for incremental token prediction tasks because of their bidirectional nature. Nor can they fill in an arbitrary amount of words.\n\n\n\n\n  \n  Comparison between architectures of influential models from different modelling methods. (from left to right) BERT is an MLM, Original Transformer is a Seq2Seq model, and LLaMA is a CLM.\n\n\nBERT (Bidirectional Encoder Representations from Transformers) model is highly effective in document embedding. Both BERT and ELMo (Embeddings from Language Models) have been instrumental in advancing the field of natural language processing and continue to be widely used in a variety of applications.\nSequence-to-Sequence Models (Seq2Seq)\nThe Sequence-to-Sequence models (Seq2Seq) aim to transform an input sequence (source) into a new one (target), and both sequences can be of arbitrary lengths. Intuitively, it works like translating a sentence from one language to another  the input and output sentences don't have to be the same length, but they do relate to one another.\nSeq2Seq models are typically composed of an encoder-decoder architecture, which can be based on Transformers or Recursive Neural Networks (RNNs). The encoder processes the input sequence and compresses it into a latent representation, and the decoder then generates the output sequence from this representation. It is a common sentiment that RNN-based models, while being more expensive (and poorly parallelizable)32, are better than transformer-only models. Thus, various works such as RWKV try to combine the best of both worlds to create hybrid models.\nThese models can generally generate coherent, much larger output based on input, making them suitable for tasks like summarization, translation, and question answering.\n\n\n\n\n  \n  Visualization of encoding and decoding flow of an Seq2Seq model.\n\n\nA popular example of a Seq2Seq model is T5 (Text-to-Text Transfer Transformer) which during training frames all NLP tasks (such as translation, classification, summarization, and more) into text-to-text problems. Doing so, allows it to learn patterns useful for a variety of tasks. Another popular example is BART (Bidirectional and Auto-Regressive Transformers) which is pre-trained by corrupting text and forcing it to reconstruct the original, which improves its text comprehension. These models have shown impressive results on a wide range of tasks, with only a fraction of parameters they can outperform CLMs on various tasks. \nThe Current State-of-the-Art\nIn the current landscape of large language models (LLM), transformer-based architectures largely steal the limelight. If you are already wondering whats working under the hood, we're planning on taking a deeper dive into their components in the next blog.\nThe ever-growing families of models and variants for architectures like GPT or BERT would cause anyone a headache to keep up. Besides the model architecture and [[#Tasks|modeling methods]] we have the label of foundational models to help us further organize our taxonomy. The foundational models are the Swiss army knives of AI models. Unlike conventional AI systems, they are trained broadly to be adapted to a variety of tasks with minimal labeled data. The core idea is that if you need more performance at a specialized task, you can start fine-tuning from a solid basis and not from scratch.\nThere are now many commercial and open-source options available for Causal Language Models (CLMs). Notable commercial CLMs include OpenAI's GPT,  Google's PaLM and Anthropic's Claude. GPT-4 is a particularly impressive model, with an ensemble of 8 models, each with 220 billion weights. It amounts to an effective size of 1.7 trillion parameters while providing reasonable latency.\nOn the open-source side, Meta's Meta's LLaMA and Mistral have gained significant popularity. LLaMA models are available in a range of sizes, from 7 to 70 billion weights. This gives companies the flexibility to choose the model that best fits their needs or to fine-tune it themselves. The community has also developed many tools and optimizations to facilitate running LLaMA.\nWhen picking your model, one should always consider the use case and the amount of effort you are willing to spend on it. There are various benchmarks such as Huggingface's Open LLM Leaderboard and Massive Text Embedding Benchmark (MTEB) Leaderboard that evaluate both open source and commercial models performance an various tasks. \nFor open source models, however, it's worth noting that both LLaMA and Mistral models are trained on English text corpus, potentially impacting their performance on tasks in languages other than English.\nAddressing Limitations of LLMs\nAs exciting as Large Language Models (LLMs) may be, they're not a one-size-fits-all solution. Just like you wouldn't use a hammer to drive a screw, there are many tasks that LLMs are well-suited for, and equally as many that they aren't. Let's take a look at some limitations posed with LLMs and what techniques exist to work around.\nRetrieval Augmented Generation\nA common challenge with LLMs is their ability  or rather, inability  to accurately recall things from memory. Despite their impressive capacity, these models don't actually \"know\" anything. They generate text based on patterns they've learned during training, which can sometimes lead to them making stuff up (a phenomenon referred to as \"hallucination\").\nTo counteract this, we can use techniques like Retrieval Augmented Generation (RAG). This approach involves retrieving documents related to a given prompt and feeding them into the LLM to provide the correct context for answering the question.\nThis retrieval process can be done through semantic or vector searches, and the exciting part is, that it can be applied to your custom data as well as external systems like Google Search, essentially giving the LLM a searchable \"knowledge base\" to draw from.\n\n\n\n\n  \n  Retrieval Augmented Generation workflow. Image from AWS Sagemaker Docs\n\n\nLLMs, despite their sophistication, still fall short when it comes to tasks like performing math calculations or executing code. A model won't be able to solve complex mathematical equations or compile and run a piece of Python code without some external help.\nThis is where \"Tools\" come to the rescue, it is another key concept related to LLMs. This involves connecting the LLM to external programs by exposing their API interface within the input context. LLM can call these tools to perform the specialized tags by writing API calls which are executed as part of the generation process.\nA prime example of this concept in action is ChatGPT plugins, which enhances the capabilities of ChatGPT by allowing it to reach out to a suite of community-made plugins. Similarly, Langchain is a more developer-focused platform, that creates API abstractions and pre-built blocks to incorporate this functionality into your application.\nExtending the reach of LLMs even further is the integration of multiple modalities, such as vision and audio. These components convert inputs like images or sound into latent representations, a universal language that our LLM understands.\nCLIP, a breakthrough technology from OpenAI, revolutionized the way we bridge the gap between text and images. Similarly, GPT-4V(ision) and Large Language and Vision Assistant (LLaVA) expand the capabilities of LLMs to comprehend and reason over images.\nChat and Agents\nWe have all become familiar with LLMs through user-friendly interfaces like ChatGPT. Traditionally, LLMs provide a single answer as a completion to the input provided. However, various variants are fine-tuned or use prompt engineering to respond in a chat format, allowing for these interactive conversations.\nTo address the limitation of LLMs being limited to single-turn conversations, AI agents are designed as systems consisting of multiple LLM agents, each instructed with their specific task. These agents communicate with each other over a chat interface, moderated by AI. By working together, these LLM agents form a collaborative machine that can work towards completing a certain task. \n\n\n\n\n  \n  An example of a conversation flow between a python code execution agent, progamming agent and the user. (From AutoGen)\n\n\nThis concept is explored in-depth in the article Introduction to Autonomous Agents in AI. This collaborative approach has been implemented in projects like ChatDev, which in true spirit of Conway's law models agents as a company designed to tackle specific tasks, and Autogen by Microsoft, which provides developer tools to create your agent-based applications.\nYour Own Tasks\nThere may be instances where you find that LLMs are not producing satisfactory results for your specific task. However, there are several strategies you can employ to address this.\nOne simple trick can be to rephrase your task. The choice of phrasing has a significant influence on how the model responds. Similarly, applying prompt engineering techniques, like few-shot prompting by providing some examples, can prove useful, giving the model hints about what kind of output you're hoping for.\nYou can also experiment with different completion regimens such as introducing human-in-the-loop agents. This approach mixes AI-generated completions with human guidance to ensure the outputs align with your expectations.\nConclusion\nWe've covered a lot of ground in this blog series on large language models. By now, you should have a solid grasp of the key concepts underlying LLMs - their inputs, how to apply them for different tasks, and their capabilities. \nI hope you've found this exploration illuminating. If you're eager to go deeper into any of the concepts we've discussed, I've included some additional resources below. Feel free to check those out while I work on the next installments.\nIf you have any other questions as you continue your LLM journey, don't hesitate to reach out. I'm always happy to help explain concepts or provide guidance on applying LLMs in business contexts. Whether you need help building an LLM pipeline from scratch, measuring impact and ROI, scaling them up for production, or determining the best use cases for your needs, I'm here. LLMs are powerful tools, but it takes thoughtful implementation to unlock their full potential.\nResources\n\nStart building RAG systems on AWS: \n\nQuestion Answering with your own data, LLMs and Java: Meet Langchain4j - Luminis\nImprove LLM responses in RAG use cases by interacting with the user | AWS Machine Learning Blog\n\n\nStart building multimodal applications:\n\nSearching through images using the CLIP model - Luminis\n\n\nAwesome LLM Tools:\n\nLangChain\nGitHub - microsoft/semantic-kernel: Integrate cutting-edge LLM technology quickly and easily into your apps\n\n\nStart Building Autonomous LLM Applications:\n\n[GitHub - OpenBMB/ChatDev: Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration)](https://github.com/OpenBMB/ChatDev\nGitHub - microsoft/autogen: Building LLM Agent Applications\n\n\nWork on your prompts: Prompt Engineering Guide\n\n","id":"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/","title":"A Comprehensive Introduction to Large Language Models"},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"body":"\nOriginaly published as part of Luminis Data Blog.\n\nIntroduction\nIn this blog, we will explore how to ensure data quality in a Spark Scala ETL (Extract, Transform, Load) job. To achieve this, we will leverage Deequ, an open-source library, to define and enforce various data quality checks.\nIf you need a refresher on data quality and its importance in data processing pipelines, you can refer to our previous blog post, Introduction to Data Quality. To recap, data quality is essential for accurate data analysis, decision-making, and achieving business objectives. It involves maintaining clean and standardized data that meets expectations. Ensuring data quality requires measuring and testing the data at different stages of the data pipeline. This may include unit testing, functional testing, and integration testing. A few testable properties of data are schema, freshness, quality, and volume which we will focus on in this blog.\nTo illustrate these concepts, we will use a mock dataset based on the Iowa Liquor Sales Dataset as a running example. The dataset as well as the complete code for this blog can be found in the following GitHub repository.\nThe rest of the blog is structured as follows:\n\nTechnologies\nSetup\nThe Dataset\nBuilding Schema Checks\nProfiling Your Data\nAdding Data Quality Checks\nCollecting Data Quality Metrics\nGracefully Handling Data Changes\nAnomaly Detection\nConclusion\n\nTechnologies\nEnsuring data quality in Spark can be achieved using various tools and libraries. One notable option is Deequ, an open-source library developed by AWS. It is a simple, but featureful tool that integrates well into AWS Glue or other Spark runtimes. By incorporating Deequ into our pipeline, we can perform schema checks, validate quality constraints, detect anomalies, collect quality metrics for monitoring, and utilize data profiling to gain insights into the properties of our data. Deequ effectively translates high-level rules and metrics into optimized Spark code, using the full potential of your Spark cluster.\nOther popular choices for data quality testing are tools like Great Expectations and Soda Core. These tools are rich in features, but also require additional configuration and setup, which may be explored in future blogs. For users already working within an AWS Glue ecosystem, exploring options that are tightly integrated with Glue, such as Deequ, can be more convenient and seamless.\nFor brevity, we will focus on adding data quality to bare-bones Spark ETL scripts. While the implementation is similar if you are using AWS Glue, we won't cover it in this blog. Instead, you can find an example glue script in the code repository.\nSetup\nTo begin, you need to have a working Scala development environment. If you don't, install Java, Scala, and sbt (Scala Build Tool). For Linux x86 the installation would look as follows:\n# Install Java (on Debian)\nsudo apt install default-jre\n\n# Install Coursier (Scala Version Manager)\ncurl -fL https://github.com/coursier/coursier/releases/latest/download/cs-x86_64-pc-linux.gz | gzip -d &gt; cs &amp;&amp; chmod +x cs &amp;&amp; ./cs setup\n\n# Install Scala 2.12 and sbt\ncs install scala:2.12.15 &amp;&amp; cs install scalac:2.12.15\n\nNext, download a compatible Apache Spark distribution (version 3.3.x is recommended) and add the bin folder to your system path. If you can run spark-submit, you are all set.\n# Download Spark\ncurl https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz --output hadoop.tgz\ntar xvf hadoop.tgz\nmv spark-3.3.2-bin-hadoop3 /usr/local/spark\n\n# Add the following line to your .bashrc (adds Spark to PATH)\nexport PATH=\"$PATH:/usr/local/spark/bin\"\n\nSample Script\nIf you haven't already, clone the example project and open it in your editor of choice.\ngit clone git@github.com:EgorDm/deequ-spark-example.git\n\nYou will find an empty example Spark script that reads a CSV file and writes it in parquet format to the output path. It takes the input path, output path and a path for metric storage as command line arguments.\ndef main(sysArgs: Array[String]): Unit = {  \n\t// Parse job arguments  \n\tval args = Map(  \n\t\t\"input_file_path\" -&gt; sysArgs(0),  \n\t\t\"output_file_path\" -&gt; sysArgs(1),  \n\t\t\"metrics_path\" -&gt; sysArgs(2)  \n\t)  \n\t  \n\t// Read the CSV input file  \n\tval rawDf = spark.read  \n\t\t.option(\"header\", \"true\")  \n\t\t.csv(args(\"input_file_path\"))  \n\t  \n\tlogger.info(s\"Do some preprocessing\")  \n\t  \n\t// Write the result to S3 in Parquet format  \n\trawDf.write  \n\t\t.mode(\"overwrite\")  \n\t\t.parquet(args(\"output_file_path\"))  \n}\n\nCompile the script with the following command, which will output the jar as target/scala-2.12/glue-deequ_2.12-0.1.0.jar.\nsbt compile &amp;&amp; sbt package\n\nRunning this Spark job is straightforward:\nspark-submit \\\n\t--class EmptyExample \\  \n\t./target/scala-2.12/glue-deequ_2.12-0.1.0.jar \\  \n\t\"./data/iowa_liquor_sales_lite/year=2022/iowa_liquor_sales_01.csv\" \\  \n\t\"./outputs/sales/iowa_liquor_sales_processed\" \\  \n\t\"./outputs/dataquality/iowa_liquor_sales_processed\"\n\nInclude Deequ Library\nSince we will be using the Deequ library, it must be added as a dependency to our project. While the library is already included in the project's dependencies, it is deliberately not bundled into the compiled jar. Instead, you can use the following command to extract it to the target/libs folder, or you can download it yourself from the maven repository.\nsbt copyRuntimeDependencies\n\nPass the --jars option to the Spark job, so the library is loaded at runtime:\nspark-submit \\\n\t--jars ./target/libs/deequ-2.0.3-spark-3.3.jar \\  \n\t--class ExampleSpark \\  \n\t./target/scala-2.12/glue-deequ_2.12-0.1.0.jar \\  \n\t\"./data/iowa_liquor_sales_lite/year=2022/iowa_liquor_sales_01.csv\" \\  \n\t\"./outputs/sales/iowa_liquor_sales_processed\" \\  \n\t\"./outputs/dataquality/iowa_liquor_sales_processed\"  \n\nAfter running the command, the output parquet files are stored in outputs/sales/iowa_liquor_sales_processed and can be inspected with Spark, Pandas, or data tools like tad.\nThe Dataset\nNow that we have our example ETL script working, let's take a look at the dataset. The mock dataset is based on the Iowa Liquor Sales dataset, which is simplified and modified to contain various data issues representative of the real world.\nThe dataset is partitioned by year, where each partition introduces schema and/or distribution changes.\ndata/iowa_liquor_sales_lite/\n\tyear=2020/iowa_liquor_sales_*.csv\n\tyear=2021/iowa_liquor_sales_*.csv\n\tyear=2022/iowa_liquor_sales_*.csv\n\nAssuming that we have already conducted exploratory data analysis, we will start building our data quality checks by using the 2022 partition and will consider at the end how the other partitions impact our solution.\n\n\n\n\n  \n  Preview of Iowa Liquor Sales dataset.\n\nBuilding Schema Checks\nThe first step is validating the schema of our dataset. A schema defines the structure and organization of the data, including the names and types of columns. By performing schema checks, we can ensure that our data conforms to the expected structure and identify any inconsistencies or missing columns.\nTo define the schema, we use Deequ's RowLevelSchema class. Here, each column and its properties are defined using methods like withStringColumn, withIntColumn, withTimestampColumn, or withDecimalColumn. For our dataset, the schema is as follows:\nval schema = RowLevelSchema()  \n\t.withStringColumn(\"Invoice/Item Number\", isNullable = false)  \n\t.withStringColumn(\"Date\", isNullable = false)  \n\t.withStringColumn(\"Store Name\", isNullable = false)  \n\t.withStringColumn(\"Zip Code\", isNullable = false)  \n\t.withStringColumn(\"Vendor Name\", isNullable = false)  \n\t.withIntColumn(\"Item Number\", isNullable = false)  \n\t.withIntColumn(\"Bottles Sold\", isNullable = false)  \n\t.withDecimalColumn(\"Sale\", isNullable = false, precision = 12, scale = 2)  \n\t.withDecimalColumn(\"Volume Sold (Liters)\", isNullable = true, precision = 12, scale = 2)\n\nAfter defining the schema, it can be validated against the data (rawDf) using the RowLevelSchemaValidator.validate method.\nval schemaResult = RowLevelSchemaValidator.validate(rawDf, schema)  \nif (schemaResult.numInvalidRows &gt; 0) {  \n\tlogger.error(  \n\ts\"Schema validation failed with ${schemaResult.numInvalidRows} invalid rows. Results: ${schemaResult}\")  \n\tschemaResult.invalidRows.show(10, truncate = false)  \n\tsys.exit(1)  \n}\n\nval validDf = schemaResult.validRows\n\nThe result (schemaResult) contains two Data Frames, specifically the valid rows that conform to the schema and invalid rows that do not. In some cases, data quarantining can be applied by preserving invalid rows and moving forward. Here, we will break and display faulty data in the console instead.\nProfiling Your Data\nThe next step is data profiling, which is an essential step for understanding the characteristics and properties of your dataset. It provides insights into the structure, content, and statistical properties of the data, enabling you to identify potential issues or anomalies, and make informed decisions about data cleansing or transformation.\nDeequ provides a convenient way to profile your data using the ConstraintSuggestionRunner. Based on the analyzed data, it collects various statistics and suggests constraints using predefined rules.\nConstraintSuggestionRunner()  \n\t.onData(validDf)  \n\t.useSparkSession(spark)  \n\t.overwritePreviousFiles(true)  \n\t.saveConstraintSuggestionsJsonToPath(\n\t\ts\"${args(\"metrics_path\")}/suggestions.json\")  \n\t.saveColumnProfilesJsonToPath(\n\t\ts\"${args(\"metrics_path\")}/profiles.json\")  \n\t.addConstraintRules(Rules.DEFAULT)  \n\t.run()\n\nIn the metrics folder, profiles.json is created as output. It contains extracted statistics in a semi-structured format which can be useful for data quality checks creation, as well as, data monitoring.\n\"columns\": [  \n\t{  \n\t\t\"column\": \"Vendor Name\",  \n\t\t\"dataType\": \"String\",  \n\t\t\"isDataTypeInferred\": \"true\",  \n\t\t\"completeness\": 1.0,  \n\t\t\"approximateNumDistinctValues\": 166  \n\t},  \n\t{  \n\t\t\"column\": \"Item Number\",  \n\t\t\"dataType\": \"Integral\",  \n\t\t\"isDataTypeInferred\": \"false\",  \n\t\t\"completeness\": 1.0,  \n\t\t\"approximateNumDistinctValues\": 1469,  \n\t\t\"mean\": 59981.83674981477,  \n\t\t\"maximum\": 995530.0,  \n\t\t\"minimum\": 567.0,  \n\t\t\"sum\": 2.42866457E8,  \n\t\t\"stdDev\": 104855.01628803412,  \n\t\t\"approxPercentiles\": []  \n\t},  \n\t{  \n\t\t\"column\": \"Volume Sold (Liters)\",  \n\t\t\"dataType\": \"Fractional\",  \n\t\t\"isDataTypeInferred\": \"false\",  \n\t\t\"completeness\": 0.8992343788589775,  \n\t\t\"approximateNumDistinctValues\": 97,  \n\t\t\"mean\": 11.238700906344382,  \n\t\t\"maximum\": 1512.0,  \n\t\t\"minimum\": 0.05,  \n\t\t\"sum\": 40920.1099999999,  \n\t\t\"stdDev\": 40.87384345937876,  \n\t\t\"approxPercentiles\": []  \n\t},\n\t...\n\nThe suggestions.json includes a list with some basic data quality rule suggestions based on the profiled metrics. Some suggestions are more useful than others. I have noticed that sometimes columns with medium cardinality are mistaken for categorical variables, suggesting value constraints. Having tight checks is valuable, but be wary of overfitting your tests.\n\"constraint_suggestions\": [  \n\t{  \n\t\t...\n\t\t\"column_name\": \"Invoice/Item Number\",  \n\t\t\"current_value\": \"Completeness: 1.0\",  \n\t\t\"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",  \n\t\t\"code_for_constraint\": \".isComplete(\\\"Invoice/Item Number\\\")\"  \n\t},\n\t{  \n\t\t...\n\t\t\"column_name\": \"Volume Sold (Liters)\",  \n\t\t\"current_value\": \"Minimum: 0.05\",  \n\t\t\"rule_description\": \"If we see only non-negative numbers in a column, we suggest a corresponding constraint\",  \n\t\t\"code_for_constraint\": \".isNonNegative(\\\"Volume Sold (Liters)\\\")\"  \n\t},\n\nAdding Data Quality Checks\nNow we have identified expectations for our data, we will write the data quality checks to help us identify and address any issues or inconsistencies present in the dataset.\nThe checks are defined in groups with associated description and severity. Under the hood, the checks are translated to metric calculations and predicates that indicate success or failure based on the result of said metric.\nThe checks address different types of issues and may operate on both column and dataset level. See this file for an overview of all the supported checks. If you can't find the right check, a custom check can be written in Spark SQL with the satisfies() method.\nHere is an example set of data quality checks that are relevant to our business case.\nval checks = Seq(  \n\tCheck(CheckLevel.Error, \"Sales base checks\")  \n\t\t.hasSize(_ &gt;= 0, Some(\"Dataset should not be empty\"))  \n\t\t.isComplete(\"Invoice/Item Number\")  \n\t\t.isComplete(\"Date\")  \n\t\t.isComplete(\"Store Name\")  \n\t\t.isComplete(\"Zip Code\")  \n\t\t.isComplete(\"Vendor Name\")  \n\t\t.isComplete(\"Item Number\")  \n\t\t.isComplete(\"Bottles Sold\")  \n\t\t.isComplete(\"Sale\")  \n\t\t.isUnique(\"Invoice/Item Number\")  \n\t\t.hasPattern(\"Invoice/Item Number\", \"^INV-[0-9]{11}$\".r)  \n\t\t.hasPattern(\"Date\", \"^[0-9]{4}-[0-9]{2}-[0-9]{2}$\".r)  \n\t\t.hasPattern(\"Zip Code\", \"^[0-9]{5}$\".r)  \n\t\t.isNonNegative(\"`Bottles Sold`\")  \n\t\t.isNonNegative(\"`Sale`\")  \n\t\t.isNonNegative(\"`Volume Sold (Liters)`\")\n)\n\nThe data quality, checks can be executed using the VerificationSuite:\nvar verificationSuite = VerificationSuite()  \n\t.onData(validDf)  \n\t.useSparkSession(spark)  \n\t.overwritePreviousFiles(true)  \n\t.saveCheckResultsJsonToPath(s\"${args(\"metrics_path\")}/checks.json\")  \n\t.addChecks(checks)\n\nval verificationResult = verificationSuite.run()\nif (verificationResult.status == CheckStatus.Error) {  \n\tlogger.error(s\"Data quality checks failed. Results: ${verificationResult.checkResults}\")  \n\tsys.exit(1)  \n}\n\nRunning the checks as is, will result in a failure. The generated report (e.g., checks.json) generally provides enough information to determine which check fail and why. By examining the report, we see the following error, implying that ~1.1% of our zip codes don't follow the five-digit format.\n...\n{  \n\t\"check_status\": \"Error\",  \n\t\"check_level\": \"Error\",  \n\t\"constraint_status\": \"Failure\",  \n\t\"check\": \"Validity checks\",  \n\t\"constraint_message\": \"Value: 0.9898740429735737 does not meet the constraint requirement!\",  \n\t\"constraint\": \"PatternMatchConstraint(Zip Code, ^[0-9]{5}$)\"  \n},\n...\n\nThis is in fact correct, as the zip code column in the dataset may contain some straggling characters. This can be fixed by either reducing the check sensitivity or addressing the issues before the checks are run:\nval validDf = schemaResult.validRows  \n\t.withColumn(\"Zip Code\", F.regexp_extract(F.col(\"Zip Code\"), \"[0-9]{5}\", 0))\n\nCollecting Data Quality Metrics\nMetrics provide valuable insights into the health and quality of our data. They can help us see trends, make improvements, and find anomalies in our data. Some metrics are necessary for configured checks and are computed automatically, while others may be needed for external systems such as monitoring dashboards or data catalogs and need to be specified manually.\nThese additional metrics, need to be added manually as analyzers:\nprivate def numericMetrics(column: String): Seq[Analyzer[_, Metric[_]]] = {\n\tSeq(  \n\t\tMinimum(column),  \n\t\tMaximum(column),  \n\t\tMean(column),  \n\t\tStandardDeviation(column),  \n\t\tApproxQuantile(column, 0.5)  \n\t)\n}  \n  \nprivate def categoricalMetrics(column: String): Seq[Analyzer[_, Metric[_]]] = {  \n\tSeq(  \n\t\tCountDistinct(column),  \n\t)  \n}\n\nBelow, we create analyzers to generically compute the distribution of numeric columns.\nval analysers = (  \n\tnumericMetrics(\"Bottles Sold\")  \n\t++ numericMetrics(\"Sale\")  \n\t++ numericMetrics(\"Volume Sold (Liters)\")  \n\t++ categoricalMetrics(\"Store Name\")  \n\t++ categoricalMetrics(\"Vendor Name\")  \n\t++ Seq(  \n\t\tCompleteness(\"Bottles Sold\"),  \n\t)  \n)\n\nSimilar to quality checks, the metrics are computed using the VerificationSuite.run() method:\nvar verificationSuite = VerificationSuite()  \n\t... \n\t.saveSuccessMetricsJsonToPath(s\"${args(\"metrics_path\")}/metrics.json\")  \n\t.addRequiredAnalyzers(analysers)\n\t...\n\nThe collected metrics are written to metrics.json file, which can be loaded by external tools. Alternatively, Deequ defines a concept of metric repositories as an interface for saving the metrics to other systems in a generic manner. You can write your own repository to store the metrics in, for example, Prometheus or AWS Cloud Watch.\nAnother useful feature is KLL Sketches which supports, approximate, but highly accurate metric calculation on data by sampling.\nIncremental Computation of Metrics\nIn the realm of ETL workloads, it is rare for data engineers to reprocess the entire dataset. Typically, pipelines are designed to be incremental, processing only new data. However, if your data quality checks rely on metrics computed over the entire dataset, this can lead to a continuous increase in load on your Spark cluster.\n\n\n\n\n  \n  Instead of repeatedly running the batch computation on growing input data D, incremental computation is supported hat only needs (t) to consume the latest dataset delta D and a state S of the computation. Source: technical paper.\n\n\nTo address this challenge, Deequ introduces a concept of Algebraic states. These states store calculated metrics and the corresponding data, enabling their aggregation across multiple pipeline runs. Consequently, only the incremental data needs to be processed, significantly reducing the computational burden.\nWe demonstrate this by adding complete dataset checks within our incremental ETL script. The first step is to record incremental metrics in a temporary in-memory state provider:\nval incrementalStateProvider = InMemoryStateProvider()\n\nval verificationResult = VerificationSuite()\n\t...\n\t.saveStatesWith(incrementalStateProvider)  \n\t...\n\nTo load the aggregated state from a persistent provider, a persistent state provider is needed. Additionally, we check if the state already exists to determine whether it should be included in the aggregation, specifically necessary for first pipeline run:\n// Initialize state for incremental metric computation  \nval completeStatePath = s\"${args(\"metrics_path\")}/state_repository/\"\nval completeStateProvider = HdfsStateProvider(spark, s\"${completeStatePath}/state.json\", allowOverwrite = true)\n\n// Determine if the complete state already exists\nval fs = FileSystem.get(spark.sparkContext.hadoopConfiguration)  \nval aggregateStates = try {  \n\tfs.listFiles(new Path(completeStatePath), false).hasNext  \n} catch {  \n\tcase _: FileNotFoundException =&gt; false  \n}\n\nNow, once again, we can run VerificationSuite, but this time we use the providers to load state data. Consequently, the checks and metrics are computed and merged over the aggregated state, which, in this case, represents the complete dataset:\n// Merge incremental metrics with complete metrics, and run data quality checks  \nval completeChecks = Seq(  \n\tCheck(CheckLevel.Error, \"Sales complete checks\")  \n\t\t.hasSize(_ &gt;= 0, Some(\"Dataset should not be empty\"))  \n)\n\nlogger.info(\"Running complete dataset checks\")  \nval completeVerificationResult = VerificationSuite.runOnAggregatedStates(  \n\tvalidDf.schema,  \n\tcompleteChecks,  \n\tif (aggregateStates) Seq(completeStateProvider, incrementalStateProvider)  \n\telse Seq(incrementalStateProvider),  \n\tsaveStatesWith = Some(completeStateProvider)  \n)\nif (completeVerificationResult.status == CheckStatus.Error) {  \n\tlogger.error(s\"Complete data quality checks failed. Results: ${completeVerificationResult.checkResults}\")  \n\tsys.exit(1)  \n}\n\nThis feature provides granular control over metric computation and therefore supports a multitude of implementations. For instance, you may choose to save the state only when the entire pipeline succeeds, or you may want to perform anomaly detection on the complete dataset.\nGracefully Handling Data Changes\nWhen working with external data sources, it's common for changes to occur, which can lead to failed checks if not properly handled. To ensure backward compatibility and smooth data processing, there are two options you can consider:\nFilterable Constraint Checks: these are conditional checks that are only executed if a specific condition is satisfied, such as when the input data is from an older dataset version. This allows you to accommodate changes in the data structure while still maintaining compatibility.\nval checks = Seq(  \n\tCheck(CheckLevel.Error, \"Sales base checks\")\n\t\t...,\n\tCheck(CheckLevel.Error, \"Legacy checks\")\n\t\t.hasPattern(\"Date\", \"^[0-9]{2}/[0-9]{2}/[0-9]{4}$\".r)\n\t\t.where(\"year &lt; 2022\")\n)\n\nSplitting by Data Version: Unfortunately, conditional checks are not applicable for schema checks. Cases such as column addition or deletion need to be addressed separately. In such cases, it's recommended to keep your data versions close at hand and use them as a discriminator to run various checks for different versions. Splitting by version enables you to have granular control over the checks while still keeping the code reusability.\nAnomaly Detection\nAnomaly detection is a crucial aspect of data quality testing that helps identify unexpected or unusual patterns in the data based on historical observations. Deequ provides several anomaly detection strategies that can be applied to different aspects of the data.\nBefore applying anomaly detection, it is important to store the metrics in a persistent repository. This ensures that historical metrics are available for comparison and trend analysis. In the code snippet below, we use a FileSystemMetricsRepository to store the metrics in a file system location:\nval metricsRepository: MetricsRepository =\n      FileSystemMetricsRepository(spark, s\"${args(\"metrics_path\")}/metrics_repository.json\")\n\nvar verificationSuite = VerificationSuite()  \n\t... \n\t.useRepository(metricsRepository)\n\t...\n\nOnce at least one data point is collected and stored in the metrics repository, we can apply anomaly detection strategies.\nOne useful application of anomaly detection is keeping the data volume in check. If your dataset is expected to grow at a predictable pace or remain stationary, you can add anomaly detection on the row count. This helps identify unexpected changes introduced by external systems or transformation scripts.\nvar verificationSuite = VerificationSuite()  \n\t... \n\t.addAnomalyCheck(\n        RelativeRateOfChangeStrategy(maxRateIncrease = Some(2.0)),\n        Size(),\n        Some(AnomalyCheckConfig(\n\t        CheckLevel.Warning,\n\t        \"Dataset doubling or halving is anomalous\"\n        ))\n    )\n\t...\n\nSimilarly, anomaly detection can be applied to specific columns where you have knowledge about the expected distribution or behavior of the data.\nWhen an anomaly is found, you have the option to handle it based on the severity of the issue. If the anomaly is critical, you can stop the pipeline to avoid propagating the issue further, or if the anomaly is not severe, you can emit a warning to your monitoring systems for further investigation.\nBy incorporating anomaly detection into your data quality checks, you can proactively identify and address unexpected or unusual patterns in your data, ensuring the overall quality and reliability of your data pipelines.\nConclusion\nIn this blog, we have set up a data quality checking solution for our Spark ETL pipeline by incorporating the open-source library Deequ. We have covered how one can use Deequ for schema checking, data profiling, quality constraints testing, quality metric collection, and anomaly detection.\nIf you prefer writing scripts in Python (i.e., PySpark), then PyDeequ may be of help, which is a Python library for Deequ. At the time of writing this blog, this library is a bit behind and doesn't yet support some features we have discussed.\nCheck out the previous blog Introduction to Data Quality if you haven't yet, which may give you ideas on how to implement your data quality checks.\nMore Resources\n\nTest data quality at scale with Deequ | AWS Big Data Blog\nBuilding a serverless data quality and analysis framework with Deequ and AWS Glue | AWS Big Data Blog\nAutomating Large-Scale Data Quality Verification - Original Deequ Technical Paper\nAWS is currently building an integrated solution for data quality checking in AWS Glue. It still lacks many features of Deequ, but it is worth keeping an eye on this one as it is in active development.\n\nData Quality  AWS Glue Data Quality Amazon Web Services\n\n\nSee more examples on Deequ GitHub page\n\n","id":"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/","title":"Data Quality Testing with Deequ in Spark"},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"body":"\nOriginaly published as part of Luminis AI Blog.\n\nIntroduction\nSageMaker is a loved and feared AWS service. You can do anything with it, from building data pipelines, to training machine learning models, to serving said models to your customers. Because of this, there is a range of approaches for any of these problems, which can often be a source of confusion on how to proceed.\nIn this blog, I clear up one such confusion about the deployment of SageMaker pipelines. I show you how to write your own pipeline definitions and how to deploy them using AWS CDK into your SageMaker domain.\nIf you are not yet working with AWS SageMaker I highly encourage you to try it out before proceeding with this walkthrough, specifically because we will be addressing some quite advanced concepts.\nWhat is SageMaker?\nBefore we delve into the how to of deploying SageMaker Pipelines using AWS CDK, its essential to understand what SageMaker is and what it brings to the table.\nAmazon SageMaker is a fully managed machine learning service provided by AWS. Its a comprehensive service that covers a wide range of machine learning tasks. It assists with data preparation, provides a notebook development environment, handles endpoint deployment, provides tools for model evaluation and much more. In essence, its a one-stop-shop for machine learning operations, designed to simplify the process of building, training, and deploying machine learning models.\nHowever, these components, while individually powerful, need a maestro to orchestrate them into a cohesive workflow. Thats where SageMaker Pipelines come in. They bridge the gap between these elements, ensuring they work together seamlessly. This orchestration acts as the connecting piece in your MLOps workflow, reducing the complexity and enhancing the manageability of your projects.\nWhat is SageMaker Pipelines?\nSageMaker Pipelines is a versatile service to orchestrate various tasks within an ML model lifecycle. Each pipeline consists of interconnected steps, each of which can run a configured docker container within SageMaker runtime or call one of the services within SageMaker. A few notable features include, but are not limited to:\n\nAllows using custom docker images from AWS ECR.\nCan seamlessly pass large files or metrics between various steps.\nSupport has a Local Mode for testing the pipelines and containerized steps locally.\nIntegrates with services such as AWS Athena and SageMaker Feature Store gethering the necessary (training) data.\nExecutable from services such as AWS StepFunctions and AWS Lambda using AWS SDK.\n\n\n\n\n\n  \n  SageMaker Pipeline Graph\n\nA High Level Overview\nBefore we delve into the specifics, it is beneficial to understand the overall structure of our deployment. The following diagram illustrates the components involved in this blog:\n\n\n\n\n  \n  What we will be building.\n\n\nOne important aspect to note is that the SageMaker Pipeline does not directly depend on the SageMaker domain. This is correct, the pipeline is a standalone resource, and can be launched programmatically using the AWS SDK or step functions, which is useful in minimal setups.\nHowever, for manual launches, a SageMaker workspace is required. This is where the SageMaker domain becomes necessary.\nTherefore, to ensure a comprehensive understanding of the process, we will also cover the creation of a SageMaker domain in this blog. This will provide a complete overview of the deployment process, equipping you with the knowledge to effectively manage your machine learning projects.\nSetting Up Your Infrastructure\nIn this section, we will focus on the initial steps required to set up the necessary infrastructure for our project. The first task involves creating a CloudFormation project which will deploy our AWS resources including: SageMaker domain, users, data buckets and optionally the VPC.\nFor those interested in the complete code, it is available on Github.\nCreate a VPC (optional)\nIf youve already got a VPC up and running, youre one step ahead. Just update the vpc_name in the cdk.json file and feel free to skip this section. However, if youre looking around and realizing youre VPC-less, dont fret. Weve got you covered.\nCreating a SageMaker domain requires a VPC. By adding the following snippet to your infrastructure CDK stack, will create one for you.\n\nNote that this particular VPC comes with a public IP. Be aware that this could incur some running costs.\n\nvpc = ec2.Vpc(\n    self,\n    id=\"VpcConstruct\",\n    ip_addresses=ec2.IpAddresses.cidr(\"10.0.0.0/16\"),\n    vpc_name=f\"{self.prefix}-vpc\",\n    max_azs=3,\n    nat_gateways=1,\n    subnet_configuration=[\n        ec2.SubnetConfiguration(\n            cidr_mask=24,\n            name=\"Public\",\n            subnet_type=ec2.SubnetType.PUBLIC,\n        ),\n        ec2.SubnetConfiguration(\n            cidr_mask=23,\n            name=\"Private\",\n            subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS,\n        ),\n        ec2.SubnetConfiguration(\n            cidr_mask=24,\n            name=\"Isolated\",\n            subnet_type=ec2.SubnetType.PRIVATE_ISOLATED,\n        ),\n    ],\n)\n\nDeploying SageMaker Domain\nFirst things first, before we get into the details of creating a SageMaker domain, we need to establish a default role that all users will assume. This can be fine-tuned or overridden later, depending on your specific use case. Heres how you can create an execution role:\nrole = iam.Role(\n    self, 'SagemakerExecutionRole',\n    assumed_by=iam.ServicePrincipal('sagemaker.amazonaws.com'),\n    role_name=f\"{self.prefix}-sm-execution-role\",\n    managed_policies=[\n        iam.ManagedPolicy.from_managed_policy_arn(\n            self,\n            id=\"SagemakerFullAccess\",\n            managed_policy_arn=\"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\"\n        ),\n    ],\n)\n\nNow, lets talk about storage. In SageMaker, scripts, notebooks, and similar resources are all stored in an S3 bucket. By default, SageMaker creates one centralized storage bucket for code and data when you create it using AWS console.\nWe on the other hand will create a separate source and data buckets with the following settings. Both buckets are configured to be inaccessible to the public for obvious reasons.\nself.sm_sources_bucket = s3.Bucket(\n    self,\n    id=\"SourcesBucket\",\n    bucket_name=f\"{self.prefix}-sm-sources\",\n    lifecycle_rules=[],\n    versioned=False,\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True,\n    # Access  \n    access_control=s3.BucketAccessControl.PRIVATE,\n    block_public_access=s3.BlockPublicAccess.BLOCK_ALL,\n    public_read_access=False,\n    object_ownership=s3.ObjectOwnership.OBJECT_WRITER,\n    enforce_ssl=True,\n    # Encryption  \n    encryption=s3.BucketEncryption.S3_MANAGED,\n)\n\nThe pipeline, by default, will assume the users role unless specified otherwise. For our purposes, the user, or the pipeline, should have enough permissions to read the code for pipeline execution and write the results to the data bucket. Its a good practice to keep the code read-only when running the pipeline, both for security reasons and to avoid any issues during runtime.\n# Grant read access to SageMaker execution role  \nself.sm_sources_bucket.grant_read(self.sm_execution_role)\n# Grant read/write access to SageMaker execution role  \nself.sm_data_bucket.grant_read_write(self.sm_execution_role)\n\nCreating a SageMaker domain itself is a very straightforward process. You just need to give it a name, attach it to the domain VPC you have from the previous steps, and attach the execution role to the default user config. If you want to specify additional security settings such as \"VPC Only\" mode, you can do it here as well. Similarly, we set tags so all the resources that start under the specific domain or user will inherit cost allocation tags accordingly.\n# Fetch VPC information  \nvpc_name = self.node.try_get_context(\"vpc_name\")\nself.vpc = ec2.Vpc.from_lookup(\n    self, id=\"ImportedVpc\",\n    vpc_name=vpc_name if vpc_name else f\"{self.prefix}-vpc\"\n)\npublic_subnet_ids = [public_subnet.subnet_id for public_subnet in self.vpc.public_subnets]\n\n# Create SageMaker Studio domain  \nself.domain = sm.CfnDomain(\n    self, \"SagemakerDomain\",\n    auth_mode='IAM',\n    domain_name=f'{self.prefix}-SG-Project',\n    default_user_settings=sm.CfnDomain.UserSettingsProperty(\n        execution_role=self.sm_execution_role.role_arn\n    ),\n    app_network_access_type='PublicInternetOnly',\n    vpc_id=self.vpc.vpc_id,\n    subnet_ids=public_subnet_ids,\n    tags=[cdk.CfnTag(\n        key=\"project\",\n        value=\"example-pipelines\"\n    )],\n)\n\nFinally, we create a user that will be used for invoking the pipeline when run manually.\n# Create SageMaker Studio default user profile  \nself.user = sm.CfnUserProfile(\n    self, 'SageMakerStudioUserProfile',\n    domain_id=self.domain.attr_domain_id,\n    user_profile_name='default-user',\n    user_settings=sm.CfnUserProfile.UserSettingsProperty()\n)\n\nRun the deploy command using CDK and there you have it! Youve successfully deployed a SageMaker domain. You can always tweak and customize your setup to better suit your projects needs, such as configuring roles, attaching ECR images and git repos for notebooks. In the next section, well dive into deploying a simple pipeline.\ncd ./infrastructure_project\n\ncdk deploy\n\nDeploying a Simple Pipeline\nThe deployment of a SageMaker pipeline is a complicated process that involves two key tasks. First, we need to generate a pipeline definition using the SageMaker SDK. Then, we deploy this definition using CloudFormation. Lets delve into the details of each task.\n\n\n\n\n  \n  Deployment Flow\n\nThe Pipeline Definition\nThe pipeline definition is a structured JSON document that instructs AWS on the sequence of steps to execute, the location for execution, the code to be run, the resources required, and the interdependencies of these steps. Essentially, it is a detailed execution plan for your machine learning pipeline.\nCreating this JSON document manually can be cumbersome and prone to errors. To mitigate this, the SageMaker SDK provides an abstraction layer that enables the use of Python code constructs to build the pipeline definition. You can start using it by adding it as a python dependency with pip install sagemaker.\nTo streamline the process of pipeline creation, we establish a base class. This class serves as an interface, which will be particularly useful when we integrate our pipeline with the rest of our CDK code. Here, we utilize Pydantic BaseModel class to enable type checking on configuration parameters you might want to pass to the pipeline.\nclass SagemakerPipelineFactory(BaseModel):\n    \"\"\"Base class for all pipeline factories.\"\"\"\n    @abstractmethod\n    def create(\n            self,\n            role: str,\n            pipeline_name: str,\n            sm_session: sagemaker.Session,\n    ) -&gt; Pipeline:\n        raise NotImplementedError\n\nWe can now proceed to write the actual pipeline declaration using the SageMaker SDK, and one such configuration parameter (pipeline_config_parameter).\nclass ExamplePipeline(SagemakerPipelineFactory):\n    pipeline_config_parameter: str\n\n    def create(\n            self,\n            role: str,\n            pipeline_name: str,\n            sm_session: sagemaker.Session,\n    ) -&gt; Pipeline:\n        ...\n\nWe proceed by declaring a runtime configurable parameter for the instance type. Then we add ScriptProcessor which defines the environment our script will be running in; including the machine instance count, the IAM execution role and the base image.\n...\n# Use the SKLearn image provided by AWS SageMaker  \nimage_uri = sagemaker.image_uris.retrieve(\n    framework=\"sklearn\",\n    region=sm_session.boto_region_name,\n    version=\"0.23-1\",\n)\n\n# Create a ScriptProcessor and add code / run parameters  \nprocessor = ScriptProcessor(\n    image_uri=image_uri,\n    command=[\"python3\"],\n    instance_type=instance_type_var,\n    instance_count=1,\n    role=role,\n    sagemaker_session=sm_session,\n)\n\nNext we define our first processing step that will use the defined processor (environment definition) to run our script with given job arguments, as well as, input and output definitions.\nprocessing_step = ProcessingStep(\n    name=\"processing-example\",\n    step_args=processor.run(\n        code=\"pipelines/sources/example_pipeline/evaluate.py\",\n\n    ),\n    job_arguments=[\n        \"--config_parameter\", self.pipeline_config_parameter\n    ],\n    inputs=[],\n    outputs=[]\n)\n\nOne single step is already enough to define a pipeline. While defining the pipeline, make sure to list its runtime parameters.\nreturn Pipeline(\n    name=pipeline_name,\n    steps=[processing_step],\n    sagemaker_session=sm_session,\n    parameters=[instance_type_var],\n)\n\nHere is the simple script that our job will be runing. It essentially prints the input job argument.\nimport argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--config_parameter\", type=str)\nargs = parser.parse_args()\n\nprint(f\"Hello {args.config_parameter}!\")\n\nAbove, we have demonstrated a minimal example for building a machine learning pipeline. If you are interested in a deeper dive of the possibilities, check out the examples in The Official Documentation.\nDeploying the Pipeline Definition\nNow that we have our pipeline definition, the next step is deploying it to your AWS Account. This is where CloudFormation comes into play, as it supports the AWS::SageMaker::Pipeline Resource. Looking at the arguments, we see that the pipeline definition should be embedded as a JSON document within the CloudFormation template. This JSON document, in our case, is emitted by SageMaker SDK, which we call during the synthesis phase of the CloudFormation stack creation.\n# Define the pipeline (this step uploads required code and packages by the pipeline to S3)  \npipeline = pipeline_factory.create(\n    pipeline_name=pipeline_name,\n    role=sm_execution_role_arn,\n    sm_session=sagemaker_session,\n)\n\npipeline_def_json = json.dumps(json.loads(pipeline.definition()), indent=2, sort_keys=True)\n\n\nNote that a new version of the code is deployed into the source bucket by SageMaker SDK before the CloudFormation stack is applied. This might raise a few eyebrows, but it will not cause issues with existing processes, as it is stored in a folder based on a derived version identifier. This does mean that you may need additional cleanup scripts later down the line.\n\nOnce we have a pipeline definition JSON, we can declare the CfnPipeline construct.\ndef create_pipeline_resource(\n        self,\n        pipeline_name: str,\n        pipeline_factory: SagemakerPipelineFactory,\n        sources_bucket_name: str,\n        sm_execution_role_arn: str,\n) -&gt; Tuple[sm.CfnPipeline, str]:\n    ...\n\n    # Define the pipeline (this step uploads required code and packages by the pipeline to S3)  \n    ...\n\n    # Define CloudFormation resource for the pipeline, so it can be deployed to your account  \n    pipeline_cfn = sm.CfnPipeline(\n        self,\n        id=f\"SagemakerPipeline-{pipeline_name}\",\n        pipeline_name=pipeline_name,\n        pipeline_definition={\"PipelineDefinitionBody\": pipeline_def_json},\n        role_arn=sm_execution_role_arn,\n    )\n    arn = self.format_arn(\n        service='sagemaker',\n        resource='pipeline',\n        resource_name=pipeline_cfn.pipeline_name,\n    )\n    return pipeline_cfn, arn\n\nFinally, we combine all everything together by passing our pipeline factory to pipeline resource creation function along with our source and data buckets.\n# Load infrastructure stack outputs as value parameters (resolved at cdk deploy time)  \nsources_bucket_name = ssm.StringParameter.value_from_lookup(\n    self, f\"/{self.prefix}/SourcesBucketName\")\nsm_execution_role_arn = ssm.StringParameter.value_from_lookup(\n    self, f\"/{self.prefix}/SagemakerExecutionRoleArn\")\n\n# Create a configured pipeline  \nself.example_pipeline, self.example_pipeline_arn = self.create_pipeline_resource(\n    pipeline_name='example-pipeline',\n    pipeline_factory=ExamplePipeline(\n        pipeline_config_parameter=\"Hello world!\"\n    ),\n    sources_bucket_name=sources_bucket_name,\n    sm_execution_role_arn=sm_execution_role_arn,\n)\n\nNow the code is complete, deploy the pipeline using the CDK commands.\ncd ./data_project\n\ncdk deploy\n\nTesting the Result\nAfter deploying both of the stacks, we can view and run our pipeline in SageMaker Studio.\nNavigate to the SageMaker service in the AWS Management Console and click on Domains. Ensure that your SageMaker domain, created as part of the infrastructure stack, is visible.\n\n\n\n\n  \n  Viewing SageMaker Domains\n\n\nInside the SageMaker domain, click on Launch near your created user and launch the SageMaker Studio.\n\n\n\n\n  \n  Viewing SageMaker Users\n\n\nIn the navigation select Pipelines to see a list of deployed pipelines. Confirm that your example pipeline is listed.\n\n\n\n\n  \n  Viewing SageMaker Pipelines\n\n\nClick on the specific pipeline (e.g., example-pipeline) to view its details and start an exectution to start and monitor your pipeline.\n\n\n\n\n  \n  Viewing SageMaker Pipeline Details\n\nConclusion\nIn this blog, we have leaned how to write a simple SageMaker Pipeline in Python and deploy it using AWS CDK. While doing so, we have deployed a SageMaker Domain and discussed how the pipeline code is stored in AWS and shared a few best practices for configuration.\nWe have only scratched the surface of what is possible with SageMaker, there are various topics that are equally important within MLOps projects such as testing your code and pipelines, local development, and automated quality monitoring.\nStay tuned for more, or contact me if you have any questions.\n","id":"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/","title":"Deploying SageMaker Pipelines Using CloudFormation"},"https://egordmitriev.dev/blog/hello-world/":{"body":"This is my first post. I'm testing the waters here.\nLet's see if LaTeX works:\n$$\n\\sum_{i=1}^{n} x_i\n$$\n","id":"https://egordmitriev.dev/blog/hello-world/","title":"Hello World!"},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"body":"\nOriginaly published as part of Luminis Data Blog.\n\nIntroduction\nWe've all heard the phrase garbage in, garbage out which highlights the importance of quality data for data-driven systems. Here, quality data can be interpreted in two ways: firstly as clean and well-standardized data that meets expectations, and secondly, as well-thought-out data that fits a particular business case. Although the latter is typically determined during the research or data strategy phase, in this blog we will focus on the former interpretation.\nMotivation\nMaintaining high-quality data is critical for accurate data analysis, decision-making, and achieving business objectives. Real-world data is often noisy and subject to constant changes, which makes maintaining data quality a challenging task. Therefore, it's crucial to identify data quality issues early on and address them before they have any effects on downstream analytics tasks or decision-making processes. One of the responsibilities of Data and MLOps Engineers is to ensure that quality is maintained throughout its lifecycle.\nMeasuring Data Quality\nTo ensure data quality throughout the data pipeline, it's important to measure and test it at different stages. A typical testing workflow in data engineering would involve several types of tests:\n\nUnit testing: focuses on testing separate components of your pipeline in isolation. For example, testing whether (a part of) an SQL or a Spark script does what it is supposed to do.\nFunctional Testing: includes data flow validation such as transformation logic validation based on business rules, as well as data integrity, which validates data based on constraints and schema checks. This type of testing occurs frequently at different stages of the pipeline (think ingestion, processing, and storage).\nIntegration Testing: ensures that the data pipeline meets the business requirements. Generally, this is done by running fake data through the pipeline and validating the result.\n\nAlthough we have covered different types of tests, it's worth noting that traditional software engineering practices only cover these points to a certain extent. For this reason, let's focus on functional testing of data and take a look at testable properties attributed to quality data.\n\nCompleteness: checks whether all expected data is present and accounted for in the data pipeline. Simple checks may test for null values, while more complex checks may also condition based on value or other columns.\nUniqueness: verifies if there are no duplicate records in the data pipeline. Duplicate records can cause issues with aggregation and analysis, leading to incorrect results.\nDistribution: focuses on closely examining the validity of column values. This may involve checks to ensure that the data falls within an accepted range or that the units used in a given column are consistent.\nValidity: enforces known invariants that should always hold true, regardless of the input data. These may be defined based on data standards or business rules. For example, the price column may never be negative, or the total column should equal to the sum of pre-tax subtotal and tax amount.\nAccuracy: measures the level to which data reflects the real world by using a verifiable source. For example, a customer phone number can be validated.\nIntegrity: takes into account relationships of data with other systems within an organization. It involves limiting changes or additions to the data that may break connections and generate orphaned records.\nConsistency: ensures that the data is accurate, and aligned with the organization's attributes. By having consistent attribute values on can building relationships between different data systems, prevent data duplication, and inconsistencies.\n\nData Observability\nHaving proper testing mechanisms set up is only the first step, as it is only natural that the data keeps evolving and may change unexpectedly. This aspect of data is not easy to tame, since you don't always have control over the source systems. That's why it's crucial to continuously test and monitor data quality, which is where Data Observability comes into play.\nThe five pillars of data observability provide good guidance criteria you would want to include in your testing and monitoring.\n\nFreshness: Does the asset use the most recent data? This is a critical aspect of data quality, as outdated or stale data can lead to incorrect decisions being made. Depending on the use case, you may need to validate that the data is fresh within a certain time window, such as the past hour or day.\nQuality: The quality checks are vital in verifying the quality of data, as they ensure that the data is in the correct format and within acceptable limits. These checks are useful for ensuring that the transformation pipeline can handle the input data, as well as, validating the output data, as is commonly applied when writing data contracts.\nVolume: Did all the data arrive? How many rows were changed? Did the dataset decrease in size? These are important questions to answer when monitoring the volume of your data pipeline. Sudden spikes or drops in volume could indicate issues with the pipeline or changes in the underlying data sources.\nSchema: The schema of a dataset defines the structure and type of each field in the data. It is often used in contracts between producers and consumers of the data. Especially when working with raw data sources, schema validation checks can help catch issues such as missing or incorrectly formatted fields, and ensure that any changes to the schema are properly communicated to downstream consumers.\nLineage: Lineage refers to the record of the origins, movement, and transformation of data throughout the data pipeline. It can answer questions about upstream sources that the data depends on and downstream assets that would be impacted by any change. The data lineage is a critical component during compliance auditing and root cause analysis.\n\n\n\n\n\n  \n  Lineage of Continent Statistics table visualized in Dagster\n\n\nYou can not test for everything, and as things inevitably break, you may be unknowingly making decisions on bad data. There is an exponential relation between lost revenue and how far down the line data issues are diagnosed.\nWhen you write tests for your data, you are testing for known unknowns. The next step you can take is testing for unknown unknowns, which on contrary are not apparent during the creation of the data systems. Detecting these issues is typically done through health checks and anomaly detection on collected metrics through simple thresholding or forecasting-based methods.\nMonitoring the percentage of faulty rows or checking whether the number of days since the last update does not exceed the historical average duration are good examples of proxy measures that can detect unknown unknowns.\n\n\n\n\n  \n  Anomaly Detection on Row Count quality metric in Soda Cloud\n\n\nPerforming data profiling by defining rule-based sets of metrics to be computed on all columns within your dataset can give you a good starting point when writing tests. Some data processing tools like OpenRefine and AWS DataBrew have built-in data profiling to aid in building cleaning transformations. Similarly, it can also be a powerful tool when combined with anomaly detection for building automated monitoring systems.\n\n\n\n\n  \n  Data Profiles in AWS DataBrew\n\n\nPresenting the data profiles, quality information, and schema as part of a dashboard or data catalog can provide a lot of value for your business. Similarly, setting the right governance structure where the issues and alerts reach the appropriate team is an important aspect of maintaining high data reliability.\nFor additional guidelines on improving data reliability, consider reviewing AWS Well-Architected Data Analytics Lens.\n\n\n\n\n  \n  Data Quality Score Cards in Monte Carlo's Data Reliability Dashboard\n\nData Testing Patterns\nWhen it comes to designing reliable data systems, it's essential to handle errors gracefully both during data quality testing and transformation. Depending on your environment, there are various testing approaches you can take. A common first concern is determining when and where to run data quality checks.\nMany cases such as ETL pipelines prefer on-demand execution where the quality of raw data is evaluated at the source or the destination after loading the data. This approach ensures that the transformation step can handle the data before actual processing is applied. Both approaches have their benefits; testing before load requires query access to the source database and may put excessive load on the application database, while loading data beforehand may result in additional latency.\nSimilarly, scheduled execution periodically tests data quality in source tables and reports if any issues arise. This approach is typically found in data warehouse solutions, where transformation is postponed until query evaluation using views.\nA notable benefit of on-demand execution is that one can immediately act on it. As such, the circuit breaker pattern is utilized to break off pipeline execution if (batch) data does not pass the error checks or an anomaly is detected. The trade-off is that the rest of the system keeps using stale or partial data until the issue is resolved.\nTo expand on this methodology, data quarantining is another related pattern that defines a flow where faulty data is set aside. The quarantined data can be used to fix the issues and reprocessed at a later date to ensure that no data loss occurs. This approach works particularly well for incremental processing pipelines or pipelines without idempotency property (i.e., processing data multiple times results in a different dataset).\nSelf-healing pipelines combine none or multiple of the mentioned properties to gracefully recover from failure. This may be as simple as retrying data submission, reprocessing the full dataset, or waiting until prerequisite data is in the system.\nChoosing Your Tools\nWe evaluated several open-source data quality tools (aside from AWS Glue) to use in our ETL pipelines. Our evaluation criteria included features, integrations, and compatibility with our existing pipeline architecture.\nGreat Expectations (GX): is the tool of choice for many data workloads. It has a large collection of community-made checks and a large collection of features. Supported integrations include some common data tools, cloud analytics (including Amazon Athena, AWS Glue, and AWS Redshift), and pandas dataframes.\n\nCodified data contracts and data docs generation\nData profiling\nThe Quality metrics are limited to what checks calculate.\nOn-demand execution\n\nAWS Deequ: is an open-source library built by AWS that covers a wide range of data quality needs. Deequ is based on the concept of data quarantining and has the functionality to filter out and store bad data at various stages of the process.\nThe tool is built in Scala on top of Apache Spark, but it has a Python bindings library which unfortunately lags quite far behind. If you don't use these tools in your stack, you will find them of limited use.\n\nAnomaly detection\nSchema checks\nData profiling\nQuality metrics calculation and merging\nOn-demand execution\n\nAWS Glue Data Quality Rules: Recently, AWS introduced a variety of data quality tools as part of their serverless computing platform Glue. The tool itself uses Deequ under the hood and provides excellent interoperability with the rest of AWS stack, such as AWS CloudWatch and result storage.\nAs of writing this article, the functionality is still in public beta, does not offer a way to store quality metric results for anomaly detection nor has a way to run the checks outside AWS glue environment (closed source). Similarly, many of the features included in deequ are not yet supported, such as quality metrics calculation or custom checks.\n\nConfiguration-based tests\nWell integrated with AWS infrastructure\n\nSoda Core: is a modern SQL-first data quality and observability tool. Similar to GX it includes a wide range of integrations. While Soda Core by itself is only for collecting metrics, a full-fledged data observability platform in form of Soda Cloud (proprietary) is provided with automatic monitoring of data quality results, data contracts, and anomaly detection.\n\nWide range of integrations\nSimple configuration\nSchema checks\nQuality measure calculation\n\nDBT Unit Tests: comes as part of the DBT which is an SQL-first tool for managing and modeling your data in data warehouses. The integrations are not limited to data sources, but also other data quality tools. The tool itself is meant for unit testing and therefore runs separately from the data flow.\n\nCustom metric calculation.\nCommunity support (resources, plugins, and integrations).\n\nApache Griffin: As a complete data quality platform, it provides an integrated dashboard for data quality analysis, and monitoring data quality over time. The quality testing runs are conducted within the tool but separate from the data flow. The integrations are limited to the Apache Stack (Kafka, Spark, Hive), and a select few other tools.\n\nStreaming data processing support\nDashboard for data quality analysis\nAnomaly detection\n\nAll listed tools have their use cases and as such there is no clear winner. For simple ETL workloads, you might want to try Deequ. In a data warehouse setting, dbt in combination with Soda or GX might prove useful. When working in a data science setting or with streaming data, GX and Apache Griffin respectively might be good choices. If your infrastructure runs on AWS, it's worth keeping an eye on developments in their Glue-based data quality tools.\nConclusion\nIn conclusion, maintaining high-quality data is essential for accurate data analysis, decision-making, and achieving business objectives. Data quality testing is a huge part of the testing process for data systems, and there are many options on how this can be implemented. In this blog, we have covered a few fundamentals, which I hope give you a starting point for exploring more on the topic and applying it in your projects. Stay tuned for part two, where we will use deequ for data quality testing within an ETL pipeline on AWS.\nMore resources\n\nBuild data lineage for data lakes using AWS Glue, Amazon Neptune, and Spline | AWS Big Data Blog\nFine, let's talk about data contracts - by Benn Stancil\nBuild a data quality score card using AWS Glue DataBrew, Amazon Athena, and Amazon QuickSight | AWS Big Data Blog\n\n","id":"https://egordmitriev.dev/blog/introduction-to-dataquality/","title":"Introduction to Data Quality"},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"body":"\nOriginaly published as part of Luminis Data Blog.\n\nIntroduction\nIn this article, we will delve into the often overlooked, but crucial aspect of data quality  data lineage.  Data lineage records the flow of data and all the transformations throughout its lifecycle, from source to destination. Understanding data lineage is vital for maintaining data integrity and transparency in data processes, making it an essential component of the data quality workflow.\nWe have previously explored the significance of data quality in our blog post, Introduction to Data Quality, which emphasizes the importance of clean and standardized data for accurate analysis and decision-making. If you are interested in getting more hands-on experience with data quality testing, you can read our previous blog post, \"Data Quality Testing with Deequ in Spark\".\nNow, we will take a closer look at data lineage, its benefits, and how it contributes to maintaining data reliability. As a whole, we aim to compile a comprehensive overview of important concepts to guide a user who is considering on implementing data lineage within their organization.\nThe rest of the blog is structured as follows:\n\nWhat is Data Lineage?\nRequirements for Effective Data Lineage\nBenefits of Data Lineage\nTools for Data Lineage\n\nWhat is Data Lineage?\nTraditionally, the data resided in a data warehouse with only a few connections to external systems. Today, the as the demand has grown, the data flows between a multitude of systems, teams, and (external) organizations. Consequently, it is easy to overlook the impact of a single change somewhere in the lifecycle of the data.\nData lineage refers to the steps a dataset took to reach its current state. It encompasses the entire lifecycle of data, from its creation or ingestion to its consumption and usage in various processes and applications. By understanding data lineage, organizations gain visibility into how data is transformed and manipulated as it moves through different systems, processes, and transformations. It is an important tool for data engineers to debug potential issues in the data flow processes.\nThere are two primary types of data lineage: table-level lineage and field-level lineage. Table-level lineage provides an overview of the tables or datasets involved in the data flow, whereas field-level lineage goes deeper, tracking the lineage of individual fields or columns within those tables.\nRequirements for Effective Data Lineage\nData lineage is just like documentation, when done right, it shouldn't put an additional burden on your development workflow, and in fact, should only enhance it. To harness the full potential of data lineage, there are some general guidelines that should be satisfied as described in Data Quality Fundamentals book by Moses, et al.:\n\nFast Time to Value: Abstracting the relationships between data objects down to the field level is crucial for quick remediation. Simply tracking at the table level may be too broad and insufficient for understanding the impact of changes and identifying specific issues. (split point)\nSecure by Design: Data lineage shouldn't directly access the data. Instead, it should rely on metadata, logs, and queries to gather information about the data flow. This simplifies the design as well ensures that no potentially private business data leaks into your documentation.\nAutomation: Manual maintenance of data lineage becomes increasingly challenging and error-prone as data pipelines become more complex. Investing in an automated data lineage generation approach saves time and reduces the risk of human error.\nIntegration with Popular Data Tools: A data project typically orchestrates data flow between multiple tools. The lineage tracking should seamlessly integrate with these technologies to create a unified view of your business, rather than dictating your workflow.\n\nBenefits of Data Lineage\nImplementing robust data lineage practices offers several benefits to organizations:\n\nCommunication and Transparency: Data lineage acts as a communication channel between data producers and data consumers. It helps bridge the gap between different teams by providing a clear understanding of the impact of broken or changed data on downstream consumers.\nImproved Data Quality and Trust: Data lineage allows organizations to build trust in their data assets. By providing visibility into the data's journey and transformation, it enhances data quality, reliability, and accuracy. This, in turn, promotes better decision-making based on trustworthy information.\nCompliance and Auditability: Data lineage supports compliance efforts by enabling organizations to demonstrate adherence to regulations, such as the General Data Protection Regulation (GDPR). It provides an audit trail of data usage and ensures transparency in data management practices.\n\nSome practical applications of data lineage in use include:\n\nDebugging: When issues arise in data analysis or reporting, data lineage can be invaluable for root cause analysis. By tracing the lineage of problematic data, analysts can identify where the issue originated and take corrective action more efficiently.\nReducing Technical Debt: Data lineage helps identify columns or fields that are no longer in use or have been deprecated. By marking and propagating these changes downstream, organizations can reduce technical debt and streamline their data pipelines.\nGovernance: With privacy regulations and data governance becoming increasingly important, data lineage provides a way to track how personally identifiable information (PII) is used within an organization. It enables organizations to understand who has access to sensitive data, how it is utilized, and ensures compliance with data protection regulations.\n\nTools for Data Lineage\nNow, let's explore some powerful tools that can help you establish and maintain a seamless data lineage process.\nOpenLineage\nOpenLineage is an emerging industry standard for data lineage tracking that is gaining traction. It is supported by the Linux Foundation, Atronomer, Collibra. It aims to establish a unified framework for capturing, managing, and sharing data lineage metadata across various tools and platforms. OpenLineage provides a consistent way to represent data lineage, making it easier to integrate with different systems and tools. You can easily incorporate it with any tool by submitting events to its API endpoint.\nOne exciting integration with OpenLineage is the combination with Marquez, a metadata service that tracks data workflows and lineage, open-sourced by WeWork. Together, they offer a simple, yet powerful solution to maintain a comprehensive and standardized view of data lineage. With this integration, you can easily trace data transformations, dependencies, and the origin of data through various data pipelines.\nMicrosoft Purview\nMicrosoft Purview is a comprehensive data governance and data cataloging solution that also offers data lineage capabilities. Purview is part of the Microsoft Azure ecosystem and integrates well with other Azure services. It allows organizations to discover, classify, and understand their data assets, making it easier to implement robust data lineage practices.\nOne notable feature of Purview is its integration with Azure Data Factory (ADF). While ADF provides some level of data lineage tracking through job dependencies, Purview enhances this functionality by offering a more unified and visual representation of data lineage across the data ecosystem.\n\n\n\n\n  \n  Data Lineage in Microsoft Purview\n\nDatahub\nDatahub is a versatile data platform that provides robust data lineage capabilities, among other features. It offers extensive integration support, making it suitable for various data environments. While it is open source, the installation is quite heavy and requires both Kafka and Elasticsearch to operate, making it a tough choice for small projects.\nDatahub can handle large-scale data lineage requirements. Data engineers and data analysts can rely on Datahub to trace data paths, identify data inconsistencies, and ensure data quality across their pipelines, making it a one-stop shop data quality tool.\n\n\n\n\n  \n  Dataset Lineage overview in DataHub\n\nSpline\nIf your organization mainly utilizes Apache Spark for data processing, Spline is an excellent tool to consider for data lineage tracking. Spline offers the ability to join lineage across multiple datasets, providing a comprehensive view of how data transformations take place.\nOne notable advantage of Spline is its compatibility with OpenLineage (currently as POC). This allows you to leverage OpenLineage's ecosystem to combine lineage across environments for visualization.\n\n\n\n\n  \n  Dataset High Level Data Lineage overview in Spline UI\n\nDBT (Data Build Tool) and Dagster\nDBT and Dagster are two powerful data tools that emphasize data-first practices and can significantly contribute to your data lineage efforts.\nDBT is a popular data transformation tool that enables data engineers and analysts to model, transform, and organize data in a structured manner. By leveraging DBT's features, you can ensure that your data lineage accurately reflects data transformations and helps maintain data integrity.\nOn the other hand, Dagster is a data orchestration tool designed to facilitate the development and management of data workflows. With Dagster, you can build robust data pipelines that capture data lineage effectively, making it easier to identify and resolve issues in your data processes.\n\n\n\n\n  \n  Data Graph in Dagster Combining FiveTran, DBT and Tensorflow Assets\n\nApache Airflow\nApache Airflow is a widely used workflow management platform that, while not a strict data lineage tool, supports data lineage indirectly through its connectors and integrations. By utilizing these connectors, you can associate data pipelines with metadata about the data sources, dependencies, and transformations.\nWhile Airflow's data lineage capabilities might not be as sophisticated as some dedicated data lineage tools, it can still play a significant role in providing visibility into your data workflows and their impact on downstream processes.\nConclusion\nIn conclusion, data lineage is a vital aspect of data quality, providing transparency in data processes and transformations. Building your lineage with best practices in mind, such as automation and the correct level of abstraction, brings a multitude of benefits like improved communication, enhanced data quality, and compliance support.\nPowerful tools are available for establishing and maintaining data lineage, offering unified frameworks for metadata management and comprehensive tracking across workflows.\nEmbracing data lineage and leveraging these tools empowers everyone within the organization to make better decisions, ensure data reliability, and build trust in their data.\n","id":"https://egordmitriev.dev/blog/overview-of-data-lineage/","title":"Overview of Data Lineage"}},"docInfo":{"https://egordmitriev.dev/":{"body":29,"title":2},"https://egordmitriev.dev/archive/":{"body":0,"title":1},"https://egordmitriev.dev/blog/":{"body":0,"title":1},"https://egordmitriev.dev/blog/comprehensive-introduction-to-large-language-models/":{"body":2046,"title":5},"https://egordmitriev.dev/blog/data-quality-testing-with-deequ-in-spark/":{"body":2025,"title":5},"https://egordmitriev.dev/blog/deploying-sagemaker-pipelines-using-aws-cdk/":{"body":1356,"title":5},"https://egordmitriev.dev/blog/hello-world/":{"body":12,"title":2},"https://egordmitriev.dev/blog/introduction-to-dataquality/":{"body":1454,"title":3},"https://egordmitriev.dev/blog/overview-of-data-lineage/":{"body":1047,"title":3}},"length":9},"lang":"English"};